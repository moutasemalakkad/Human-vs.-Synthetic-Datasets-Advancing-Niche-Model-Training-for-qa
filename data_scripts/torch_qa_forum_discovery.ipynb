{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Scraped Data (Json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>all_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>https://discuss.pytorch.org/t/why-do-i-get-typeerror-expected-np-ndarray-got-numpy-ndarray-when-i-use-torch-from-numpy-function/37525</td>\n",
       "      <td>Why do I get “TypeError: expected np.ndarray (got numpy.ndarray)”  when I use torch.from_numpy() function? Isn’t np.ndarray equivalent to numpy.ndarray? Also, there doesn’t seem to be any np.ndarray type, but only numpy.ndarray type.\\nTraceback (most recent call last): File \"test_opencv.py\", line 31, in &lt;module&gt; bounding_boxes, landmarks = detect_faces(img, pnet, rnet, onet) File \"/home/xxx/git/project/src/detector.py\", line 67, in detect_faces boxes = run_first_stage(image, pnet, scale=s, threshold=thresholds[0]) File \"/home/xxx/git/project/src/first_stage.py\", line 73, in run_first_stage img = torch.from_numpy(img).unsqueeze(0).permute(0,3,1,2).cuda().float() TypeError: expected np.ndarray (got numpy.ndarray)</td>\n",
       "      <td>[Can you share some debugging info like printing type(img) and img.dtype I wrote the same line of code and it worked for me.\\nThere has to be some bug in the data loading process of the image., Hello It seems you are getting the error because the argument to from_numpy function is a single value rather than array.\\nIn numpy, there is difference between np.array(1) and np.array([1]) and both are completely different data types.\\nTry torch.from_numpy(np.asarray(x))., Hello, I have encountered the same problem. Do you have any solutions?Thank you, Try\\ntorch.as_tensor(np.array(pil_img).astype('float'))\\nIt worked for me., Have you fix this problem? I encounter this problem too…, Could you post a minimal code snippet to reproduce this error?, I found it is because of the version of numpy…\\n\\n\\n\\n信工 刘蓬博\\n邮箱：pengbo18555@163.com\\n签名由 网易邮箱大师 定制, It’s also happening to me on numpy 1.17.4, my own solution is to downgrade to 1.16.4, thanks! it worked for me.\\nNumpy version -  1.19.5, It worked for me. Thank you @raghavendragaleppa, I was working with tabular MNIST data !!\\none possible solution that worked for me was,\\nx_train.reset_index(drop=True,inplace=True)\\nx_test.reset_index(drop=True,inplace=True)\\ny_train.reset_index(drop=True,inplace=True)\\ny_test.reset_index(drop=True,inplace=True)\\nhope it helps for those using TABULAR dataset, iam trying to run a simple dqn code for cartpole environment in my computer.                                                        This is my code updated as you said;\\n    env = gym.make('CartPole-v1')\\n    q = Qnet()\\n    q_target = Qnet()\\n    q_target.load_state_dict(q.state_dict())\\n    memory = ReplayBuffer()\\n\\n    print_interval = 20\\n    score = 0.0  \\n    optimizer = optim.Adam(q.parameters(), lr=learning_rate)\\n\\n    for n_epi in range(10000):\\n        epsilon = max(0.01, 0.08 - 0.01*(n_epi/200)) #Linear annealing from 8% to 1%\\n        s = env.reset()\\n        done = False\\n        while not done:\\n            **a = q.sample_action(torch.from_numpy(np.asarray(s)).float(), epsilon)**      \\n            s_prime, r, done, info = env.step(a)\\n            done_mask = 0.0 if done else 1.0\\n            memory.put((s,a,r/100.0,s_prime, done_mask))\\n            s = s_prime\\n\\nbut iam getting the following error again where everything is fine\\nTraceback (most recent call last):\\nFile “d:\\college\\final yr\\project\\rl-series\\dqn\\simpledqn.py”, line 114, in \\nmain()\\nFile “d:\\college\\final yr\\project\\rl-series\\dqn\\simpledqn.py”, line 93, in main\\na = q.sample_action(torch.from_numpy(np.asarray(s)), epsilon)\\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part., Thanks! This solved my issue., I think this problem may arise from torch.from_numpy(array)'s mismatching with numpy version or dtype,and use other way of generating a tensor from numpy is a solution.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>https://discuss.pytorch.org/t/w-cudaipctypes-cpp-22-producer-process-has-been-terminated-before-all-shared-cuda-tensors-released-see-note-sharing-cuda-tensors/124445</td>\n",
       "      <td>I got this warning at the end of each epoch when using multiple GPUs:\\n[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\\nBut it doesn’t seem to affect the training since the result is as good as it is.\\nBut I would still like to know what the probable cause is and how to solve it  \\nI simply use: model = torch.nn.DataParallel(model) to enable multi-GPUs.\\nBesides, I also added torch.multiprocessing.set_start_method('spawn', force=True) in my code. Don’t know whether it has any effect on this.\\nThank you for the answer in advance.</td>\n",
       "      <td>[Are you seeing the same message, if you remove the multiprocessing code (I assume this is triggering it)?, Sorry for my late response and thank you for the reply!\\nI pinned the trigger of this warning. It happens if I set num_workers &gt; 0 in torch.utils.data.DataLoader, instead of being caused by nn.DataParallel().\\nAny idea how to fix it? Is it probably due to that I set torch.multiprocessing.set_start_method('spawn', force=True)?, I have issued the same problem when setting num of workers to more then 0. @ptrblck, any solution ?, Unfortunately, I don’t have suggestions, as I don’t fully understand the use case of using torch.multiprocessing as well as multiple workers (which itself will use multiple processes), so could you explain the use case a bit more?, Hi @ptrblck, I came across the same issue and was intrigued by your remark:\\n\\n\\n\\n ptrblck:\\n\\nI don’t fully understand the use case of using torch.multiprocessing as well as multiple workers\\n\\n\\nFor one, isn’t it good to be able to process/load the data using a separate process, apart from the training process(es), in order to not tax them with extra processing load? Further, although it’s not my use case, loading the data might involve some heavy preprocessing, warranting even more than one data loader workers per training process; e.g. in the case in of some vision applications.\\nMaybe you have a completely different idea about this and give us your insight in to this topic.\\nThanks in advance., I totally agree with you and also think that multiple processes by themselves are useful, should be used for the data loading and process, and would yield a speedup in the overall training pipeline.\\nThis can be easily achieved with the num_workers argument of the DataLoader.\\nMy comment might not have been clear enough, but I was wondering about the use case to use the multiprocessing package manually in the training script as well as multiple workers (which will again spawn multiple processes, so you would end up with a “nested” multiprocessing workload), as I would imagine that using the simpler approach of setting num_workers&gt;=1 should already do the job., Ah, ok, sorry, I didn’t notice the part about using the multiprocessing package separately. I think this is because I had the same issue just using DDP and Dataloaders with num_workers &gt; 0. I get these errors just before my script exits; I already am a good citizen by using dist.barrier() to wait for all training processes to complete before exiting.\\nWhen I set the num_workers to zero the script exits smoothly without any errors. In the past I have often used multiple DataLoader workers in a DDP context and never had this issue. I’m wondering if this is something that sneaked in to a recent Pytorch release or is related to recent a CUDA version?\\nMy setup:\\n| NVIDIA-SMI 470.86 Driver Version: 470.86 CUDA Version: 11.4     |\\n\\n$ pip show torch\\nName: torch\\nVersion: 1.10.0\\n\\nThis is on a 4x V100 machine with Ubuntu.\\nIt might also be in my script of course., Ok, I dove a bit more in to this, and found the issue. In this particular instance I am using a model library where the author unfortunately had added the batch collate function as a method to the model class. Because of this the model self is also transported to the DataLoader workers.\\nWhen the training scripts exits the DataLoader worker processes are killed too, without properly dealing with the Tensors that are copied to the worker.\\nI refactored all the batch collating code out of the model class and thus made it independent of the self of the model instance. This resolved the issue, exiting the script is very smooth now!\\nSo, if anyone gets this error, it could be because your are copying the model over to the DataLoader workers without knowing it., Hi @visionscaper, I’m encountering the same issue. I’m currently using pytorch lightning to write my model. When I set the num_worker &gt; 0 in the dataloader, the warning will occur. I’m a beginner in pytorch. Could you give me some example that how did you refactor your batch collating code out of model class? I don’t know how to do it., Hi @sjtuhl, if you have a similar issue to mine, somehow your model is linked to your dataset, collate_fn or other object given to a DataLoader. Because of this, when you set num_worker &gt; 0, the model is copied to the DataLoader workers. For instance, if your dataset is a property of your model class instance (which is just bad design), not only your dataset is copied to the workers, but everything it is “attached” to as well.\\nI hope this makes sense to you. I can’t really help you without inspecting your code., Hi @visionscaper, I have the same issue as you. My data collate fn is written inside the dataset model. There are some tensors my collate_fn need, stored in the dataset model. I wonder if there is a way to avoid moving the collate_fn out and escape the error?, This warning is caused by tensors (or other objects) that are not being properly cleaned up (released) on the CUDA device before the process they belonged to was terminated.\\nAs it was for me in my case, and seems to be the case for mostly everyone else, the culprit behind this warning has to do with moving objects to, or owning objects on, the CUDA device from inside of one of the DataLoader worker processes, and the worker process being terminated before the  objects are released from CUDA.\\nMoving tensors to CUDA inside a collate_fn that is passed to a DataLoader where num_workers &gt; 0 - which just means that a child process will be created for each worker - is an example of this, and is exactly what I was doing. In my training loop then, after all the training samples were iterated through, my DataLoader worker processes would be terminated and I would get this warning.\\nAs tempting as it is to move batches to CUDA inside the collate_fn, and though it may even provide some performance gains, the potential for a memory leak or some other resource management issue along with the annoying warning made me rethink my strategy. I ended up just relocating this logic to the first line in my training loop (on CPU - main process) where I move each batch to CUDA before my forward pass which I think is generally recommended anyway - never looked back since.\\nAlternatively, if you really wanted to, you could keep whatever objects you want on the CUDA device inside your DataLoader worker processes if you set persistent_workers=True in your DataLoader constructor and not encounter this warning until your DataLoader is entirely deallocated. You may encounter other issues though like running out of memory on the GPU, but I think for some use cases, maybe doing this could be beneficial.\\nHope this helps.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>https://discuss.pytorch.org/t/determinism-in-inference/208033</td>\n",
       "      <td>I have the following code snippet. When I run the script consecutively, I get different results in prediction. Is there a setting I’m missing?\\nimport torch\\nimport numpy as np\\nimport random\\n\\n# Set the seed for all random number generators\\nseed = 42\\ntorch.manual_seed(seed)\\nrandom.seed(seed)\\nnp.random.seed(seed)\\ntorch.cuda.manual_seed(seed)\\ntorch.cuda.manual_seed_all(seed)\\n\\n# Ensure deterministic behavior\\ntorch.backends.cudnn.deterministic = True\\ntorch.backends.cudnn.benchmark = False\\n\\n# Set CUBLAS workspace config to ensure deterministic cuBLAS\\nimport os\\nos.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\\n\\ntorch.use_deterministic_algorithms(True)\\ntorch.set_num_threads(1)\\n\\n# Load the model\\nmodel = torch.jit.load('test.pt')\\nmodel = model.to(torch.device('cuda:0'))\\nmodel = model.half()\\n\\n# Create a random array\\ntorch.manual_seed(0)\\nrandom_arr = torch.randn(1,1,224, 224, 224, dtype = torch.half).to(torch.device('cuda:0'))\\npred = model(random_arr).to(torch.device('cpu')).detach().numpy()\\n\\nThe pred variable is different in each run, max. difference is about 3e-2. Any help would be appreciated. Thanks!</td>\n",
       "      <td>[Could you post a minimal and executable code snippet reproducing the issue?, Thanks for your response. Here are two scripts, please save them as script_1.py and script_2.py in the working directory. For this experiment, I’m using a model from huggingface, but the results are similar with my own segmentation model (nnU-Net).\\n# Save this as script_1.py\\n\\nimport torch\\nimport numpy as np\\nimport random\\nimport requests\\nimport pickle\\nimport argparse\\n\\nif __name__ == '__main__':\\n\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument(\"--result_filename\", help=\"location to save the result prediction\")\\n\\n    args = parser.parse_args()\\n    \\n    # Set the seed for all random number generators\\n    seed = 42\\n    torch.manual_seed(seed)\\n    random.seed(seed)\\n    np.random.seed(seed)\\n    torch.cuda.manual_seed(seed)\\n    torch.cuda.manual_seed_all(seed)\\n\\n    # Ensure deterministic behavior\\n    torch.backends.cudnn.deterministic = True\\n    torch.backends.cudnn.benchmark = False\\n\\n    # Set CUBLAS workspace config to ensure deterministic cuBLAS\\n    import os\\n    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\\n\\n    torch.use_deterministic_algorithms(True)\\n    torch.set_num_threads(1)\\n\\n    # Download the file\\n    url = 'https://huggingface.co/spaces/Xajimel/Practica3/resolve/main/unet.pth'\\n    response = requests.get(url)\\n    with open('model.pt', 'wb') as f:\\n        f.write(response.content)\\n\\n    model = torch.jit.load('model.pt')\\n    model = model.to(torch.device('cuda:0'))\\n    model = model.half()\\n\\n    # Create a random array\\n    torch.manual_seed(0)\\n    random_arr = torch.randn(1, 3, 224, 224, dtype = torch.half).to(torch.device('cuda:0'))\\n    pred = model(random_arr).to(torch.device('cpu')).detach().numpy()\\n\\n    with open(args.result_filename, 'wb') as f:\\n        pickle.dump(pred, f)\\n\\n# Save this as script_2.py\\n\\nimport pickle\\nimport numpy as np\\n\\nwith open('pred1.pkl', 'rb') as f:\\n    a = pickle.load(f)\\n\\nwith open('pred2.pkl', 'rb') as f:\\n    b = pickle.load(f)\\n\\nprint('Length of a: ', len(a))\\nprint('Length of b: ', len(b))\\n\\nprint('Shape of first element in a: ', a[0].shape)\\nprint('Shape of first element in b: ', b[0].shape)\\n\\ndiff = a[0] - b[0]\\n\\nprint('Min diff: ', np.min(diff))\\nprint('Max diff: ', np.max(diff))\\n\\nRun this with the following commands.\\npython script_1.py --result_filename pred1.pkl\\npython script_1.py --result_filename pred2.pkl\\npython script_2.py\\n\\nSomething I found interesting was that if I change the url in script_1.py to a different model (say this one), I see no differences in the prediction.\\nI wonder if the issue then is non-determinism in some layers in the nnU-Net model or the way I’m saving the model. This is how I save the model.\\nself.network = self.network.to(self.device)\\nself.network.eval()\\ntorch.use_deterministic_algorithms(True)\\ntraced_model = torch.jit.trace(self.network, torch.randn(1, 1, 224, 224, 224).to(self.device))\\ntorch.jit.save(traced_model, 'model.pt')\\n\\nLet me know what you think or if you need some more info. Thanks!, I cannot reproduce the issue and see:\\nLength of a:  1\\nLength of b:  1\\nShape of first element in a:  (5, 224, 224)\\nShape of first element in b:  (5, 224, 224)\\nMin diff:  0.0\\nMax diff:  0.0, This is what I see. I’m on torch 2.3.0+cu121 if that helps.\\nLength of a:  1\\nLength of b:  1\\nShape of first element in a:  (5, 224, 224)\\nShape of first element in b:  (5, 224, 224)\\nMin diff:  -0.01563\\nMax diff:  0.01172, @ptrblck On the machine that I was initially testing on, I see the issue on torch 2.3.0+cu121 and torch 2.4.0+cu121. On another machine, I don’t see the issue in either versions. These machines have different GPUs (earlier: A40, now: RTX 3050 Ti).\\nCould the underlying GPU make a difference?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>https://discuss.pytorch.org/t/updating-adam-optimizer-after-modifying-model-architecture/208101</td>\n",
       "      <td>import torch.nn as nn\\nimport torch\\n\\nclass Foo(nn.Module):\\n    def __init__(self, input_size=20, output_size=100):\\n        super().__init__()\\n        self.input_size = input_size\\n        self.output_size = output_size\\n\\n        self.fc0 = nn.Linear(self.input_size, 30)\\n        self.fc1 = nn.Linear(30, 40)\\n        self.fc_out = nn.Linear(40, self.output_size)\\n\\n    def increment_output_size(self, copy_idx: int):\\n        old_output_size = self.output_size\\n        old_fc_out = self.fc_out\\n\\n        self.output_size += 1\\n        self.fc_out = nn.Linear(40, self.output_size)\\n        with torch.no_grad():\\n            self.fc_out.weight.data[:old_output_size] = old_fc_out.weight.data\\n            self.fc_out.weight.data[-1] = old_fc_out.weight.data[copy_idx].clone()\\n            self.fc_out.bias.data[:old_output_size] = old_fc_out.bias.data\\n            self.fc_out.bias.data[-1] = old_fc_out.bias.data[copy_idx].clone()\\n\\n\\nif __name__ == \"__main__\":\\n    # SETUP MODEL AND OPTIMIZER\\n    model = Foo()\\n    optimizer = torch.optim.Adam(model.parameters())\\n\\n    # DO SOME TRAINING HERE (Adam optimizer will hold state stat for each parameter)\\n    # ...\\n\\n    # MODIFY MODEL\\n    model.increment_output_size(copy_idx=25)\\n\\n    # UPDATE OPTIMIZER\\n    #  1. For parameters (weights/bias) of model.fc0 and model.fc1, the state should be retained.\\n    #  2. For parameter fc_out, which is modified:\\n    #     a. for model.fc_out.weight/bias[:100], preserve the corresponding states in Adam\\n    #     b. for model.fc_out.weight/bias[101], clone the state corresponding to model.fc_out.weight[25]\\n\\n    # DO SOME MORE TRAINING HERE\\n    # ...\\n\\n    print(\"Done\")\\n\\nThe code above attempts to train a model that, throughout the training process, may dynamically modify its self.fc_out module to accommodate for increase in the number of classes. I want it so that the existing Adam optimizer can adaptively update its internal state in accordance to the model modification. This means both updating the relevant items in self.updater.optimizer.param_groups[0][\"params\"] and self.updater.optimizer.state (and other stuff, if necessary).\\nHow can I do this? Specifically:\\n\\nHow can I index the optimizer fields/keys relevant to the self.fc_out?\\nHow do I replace the relevant optimizer params and states? Is it sufficient to do self.updater.optimizer.param_groups[0][\"params\"][index_of_fc_out_weight] = model.fc_out.weight and self.updater.optimizer.state[index_of_fc_out_weight] = new_fc_out_state?\\nAre there any other fields or under-the-hood mechanisms that I need to be aware of?\\n\\nAny help is appreciated.</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>https://discuss.pytorch.org/t/weird-pytorch-profiler-output/208078</td>\n",
       "      <td>Hello,\\nI am profiling my training code and I’m struggling to understand the output. The different steps seem to be taking different amount of time and I am not sure why.\\nimage3082×1044 378 KB\\nA simplified version of my code would be:\\nwith profiler.profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], ...) as p:\\n    for x, y in training_dataloader:\\n        p.step()\\n        out = model(x)\\n        loss = loss_fn(out,y)\\n        loss.backward()\\n        optim.step()\\n        optim.zero_grad()\\n\\nScheduler is set to skip_first=10, wait=5, warmup=1, active=5, repeat=1\\nIf I then add some operation that downloads something to cpu memory such as l = loss.item() after the optimizer step, I get something like this:\\nimage3048×1050 292 KB\\nIn both scenarios the average train step is the same even though each profiler step seems to vary in time in the first case.\\nI am a bit confused by this behaviour. My hypothesis is that my profiler might be measuring the async python function calls and not the actual cuda kernels. But isn’t the point of the profiler to measure the cuda kernel time? I am interested in analysing how long does my CPU and GPU take in each part of the code, and I guess here I am just seeing the CPU?\\nIf I go down below in the GPU thread part of the profiler, I get this, which I don’t understand or is giving me too little information about how long is spent in each kernel by the gpu.\\nimage4106×798 183 KB\\nNote that this screenshot is taken for the first example where i do NOT add l = loss.item() and all the different steps are taking different time in cpu time. Yet in the GPU thread they seem to be taking the same amount of time.\\nI would appreciate any insights on why this is happening or if my intuitions are correct and what is the best way to measure how long is my GPU spending in each kernel.\\nI am using a 4090 GPU and the model is a simple UNet with 128x128 image input.\\nThanks,\\nBenet</td>\n",
       "      <td>[benoriol:\\n\\nIf I then add some operation that downloads something to cpu memory such as l = loss.item() after the optimizer step, I get something like this:\\n\\n\\nThis is expected since the item() call is synchronizing the GPU.\\n\\n\\n\\n benoriol:\\n\\nI am a bit confused by this behaviour. My hypothesis is that my profiler might be measuring the async python function calls and not the actual cuda kernels.\\n\\n\\nYes, this seems to be the case and I would expect to see different time lines: one for the host and another one for the device.\\nI’m not familiar with the native PyTorch profiler visualization as I am using Nsight Systems for profiling. You could check this post for instructions on how to use nsys., That makes sense, thanks.\\nOne more question, is there a limit to the number of async python calls that pytorch can do without waiting for the actual computation to be done in the GPU? It seems that it is doing multiple faster non-blocking calls to training steps (#16 and #17) before it starts to take longer in step #18, I assume waiting for GPU to finish the previous ones. In general, what is a good resource where I can learn more about how Pytorch works under the hood?\\nIn any case I will switch to nsys profiler, seems like a much better option. Thanks a lot., benoriol:\\n\\nOne more question, is there a limit to the number of async python calls that pytorch can do without waiting for the actual computation to be done in the GPU?\\n\\n\\nYes, the queue handling the CUDA kernel launches is limited and the host will be blocked if the queue is saturated.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category  \\\n",
       "0  Uncategorized   \n",
       "1  Uncategorized   \n",
       "2  Uncategorized   \n",
       "3  Uncategorized   \n",
       "4  Uncategorized   \n",
       "\n",
       "                                                                                                                                                                   title  \\\n",
       "0                                  https://discuss.pytorch.org/t/why-do-i-get-typeerror-expected-np-ndarray-got-numpy-ndarray-when-i-use-torch-from-numpy-function/37525   \n",
       "1  https://discuss.pytorch.org/t/w-cudaipctypes-cpp-22-producer-process-has-been-terminated-before-all-shared-cuda-tensors-released-see-note-sharing-cuda-tensors/124445   \n",
       "2                                                                                                          https://discuss.pytorch.org/t/determinism-in-inference/208033   \n",
       "3                                                                        https://discuss.pytorch.org/t/updating-adam-optimizer-after-modifying-model-architecture/208101   \n",
       "4                                                                                                     https://discuss.pytorch.org/t/weird-pytorch-profiler-output/208078   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         question  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Why do I get “TypeError: expected np.ndarray (got numpy.ndarray)”  when I use torch.from_numpy() function? Isn’t np.ndarray equivalent to numpy.ndarray? Also, there doesn’t seem to be any np.ndarray type, but only numpy.ndarray type.\\nTraceback (most recent call last): File \"test_opencv.py\", line 31, in <module> bounding_boxes, landmarks = detect_faces(img, pnet, rnet, onet) File \"/home/xxx/git/project/src/detector.py\", line 67, in detect_faces boxes = run_first_stage(image, pnet, scale=s, threshold=thresholds[0]) File \"/home/xxx/git/project/src/first_stage.py\", line 73, in run_first_stage img = torch.from_numpy(img).unsqueeze(0).permute(0,3,1,2).cuda().float() TypeError: expected np.ndarray (got numpy.ndarray)   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    I got this warning at the end of each epoch when using multiple GPUs:\\n[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\\nBut it doesn’t seem to affect the training since the result is as good as it is.\\nBut I would still like to know what the probable cause is and how to solve it  \\nI simply use: model = torch.nn.DataParallel(model) to enable multi-GPUs.\\nBesides, I also added torch.multiprocessing.set_start_method('spawn', force=True) in my code. Don’t know whether it has any effect on this.\\nThank you for the answer in advance.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           I have the following code snippet. When I run the script consecutively, I get different results in prediction. Is there a setting I’m missing?\\nimport torch\\nimport numpy as np\\nimport random\\n\\n# Set the seed for all random number generators\\nseed = 42\\ntorch.manual_seed(seed)\\nrandom.seed(seed)\\nnp.random.seed(seed)\\ntorch.cuda.manual_seed(seed)\\ntorch.cuda.manual_seed_all(seed)\\n\\n# Ensure deterministic behavior\\ntorch.backends.cudnn.deterministic = True\\ntorch.backends.cudnn.benchmark = False\\n\\n# Set CUBLAS workspace config to ensure deterministic cuBLAS\\nimport os\\nos.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\\n\\ntorch.use_deterministic_algorithms(True)\\ntorch.set_num_threads(1)\\n\\n# Load the model\\nmodel = torch.jit.load('test.pt')\\nmodel = model.to(torch.device('cuda:0'))\\nmodel = model.half()\\n\\n# Create a random array\\ntorch.manual_seed(0)\\nrandom_arr = torch.randn(1,1,224, 224, 224, dtype = torch.half).to(torch.device('cuda:0'))\\npred = model(random_arr).to(torch.device('cpu')).detach().numpy()\\n\\nThe pred variable is different in each run, max. difference is about 3e-2. Any help would be appreciated. Thanks!   \n",
       "3  import torch.nn as nn\\nimport torch\\n\\nclass Foo(nn.Module):\\n    def __init__(self, input_size=20, output_size=100):\\n        super().__init__()\\n        self.input_size = input_size\\n        self.output_size = output_size\\n\\n        self.fc0 = nn.Linear(self.input_size, 30)\\n        self.fc1 = nn.Linear(30, 40)\\n        self.fc_out = nn.Linear(40, self.output_size)\\n\\n    def increment_output_size(self, copy_idx: int):\\n        old_output_size = self.output_size\\n        old_fc_out = self.fc_out\\n\\n        self.output_size += 1\\n        self.fc_out = nn.Linear(40, self.output_size)\\n        with torch.no_grad():\\n            self.fc_out.weight.data[:old_output_size] = old_fc_out.weight.data\\n            self.fc_out.weight.data[-1] = old_fc_out.weight.data[copy_idx].clone()\\n            self.fc_out.bias.data[:old_output_size] = old_fc_out.bias.data\\n            self.fc_out.bias.data[-1] = old_fc_out.bias.data[copy_idx].clone()\\n\\n\\nif __name__ == \"__main__\":\\n    # SETUP MODEL AND OPTIMIZER\\n    model = Foo()\\n    optimizer = torch.optim.Adam(model.parameters())\\n\\n    # DO SOME TRAINING HERE (Adam optimizer will hold state stat for each parameter)\\n    # ...\\n\\n    # MODIFY MODEL\\n    model.increment_output_size(copy_idx=25)\\n\\n    # UPDATE OPTIMIZER\\n    #  1. For parameters (weights/bias) of model.fc0 and model.fc1, the state should be retained.\\n    #  2. For parameter fc_out, which is modified:\\n    #     a. for model.fc_out.weight/bias[:100], preserve the corresponding states in Adam\\n    #     b. for model.fc_out.weight/bias[101], clone the state corresponding to model.fc_out.weight[25]\\n\\n    # DO SOME MORE TRAINING HERE\\n    # ...\\n\\n    print(\"Done\")\\n\\nThe code above attempts to train a model that, throughout the training process, may dynamically modify its self.fc_out module to accommodate for increase in the number of classes. I want it so that the existing Adam optimizer can adaptively update its internal state in accordance to the model modification. This means both updating the relevant items in self.updater.optimizer.param_groups[0][\"params\"] and self.updater.optimizer.state (and other stuff, if necessary).\\nHow can I do this? Specifically:\\n\\nHow can I index the optimizer fields/keys relevant to the self.fc_out?\\nHow do I replace the relevant optimizer params and states? Is it sufficient to do self.updater.optimizer.param_groups[0][\"params\"][index_of_fc_out_weight] = model.fc_out.weight and self.updater.optimizer.state[index_of_fc_out_weight] = new_fc_out_state?\\nAre there any other fields or under-the-hood mechanisms that I need to be aware of?\\n\\nAny help is appreciated.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Hello,\\nI am profiling my training code and I’m struggling to understand the output. The different steps seem to be taking different amount of time and I am not sure why.\\nimage3082×1044 378 KB\\nA simplified version of my code would be:\\nwith profiler.profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], ...) as p:\\n    for x, y in training_dataloader:\\n        p.step()\\n        out = model(x)\\n        loss = loss_fn(out,y)\\n        loss.backward()\\n        optim.step()\\n        optim.zero_grad()\\n\\nScheduler is set to skip_first=10, wait=5, warmup=1, active=5, repeat=1\\nIf I then add some operation that downloads something to cpu memory such as l = loss.item() after the optimizer step, I get something like this:\\nimage3048×1050 292 KB\\nIn both scenarios the average train step is the same even though each profiler step seems to vary in time in the first case.\\nI am a bit confused by this behaviour. My hypothesis is that my profiler might be measuring the async python function calls and not the actual cuda kernels. But isn’t the point of the profiler to measure the cuda kernel time? I am interested in analysing how long does my CPU and GPU take in each part of the code, and I guess here I am just seeing the CPU?\\nIf I go down below in the GPU thread part of the profiler, I get this, which I don’t understand or is giving me too little information about how long is spent in each kernel by the gpu.\\nimage4106×798 183 KB\\nNote that this screenshot is taken for the first example where i do NOT add l = loss.item() and all the different steps are taking different time in cpu time. Yet in the GPU thread they seem to be taking the same amount of time.\\nI would appreciate any insights on why this is happening or if my intuitions are correct and what is the best way to measure how long is my GPU spending in each kernel.\\nI am using a 4090 GPU and the model is a simple UNet with 128x128 image input.\\nThanks,\\nBenet   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 all_answers  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [Can you share some debugging info like printing type(img) and img.dtype I wrote the same line of code and it worked for me.\\nThere has to be some bug in the data loading process of the image., Hello It seems you are getting the error because the argument to from_numpy function is a single value rather than array.\\nIn numpy, there is difference between np.array(1) and np.array([1]) and both are completely different data types.\\nTry torch.from_numpy(np.asarray(x))., Hello, I have encountered the same problem. Do you have any solutions?Thank you, Try\\ntorch.as_tensor(np.array(pil_img).astype('float'))\\nIt worked for me., Have you fix this problem? I encounter this problem too…, Could you post a minimal code snippet to reproduce this error?, I found it is because of the version of numpy…\\n\\n\\n\\n信工 刘蓬博\\n邮箱：pengbo18555@163.com\\n签名由 网易邮箱大师 定制, It’s also happening to me on numpy 1.17.4, my own solution is to downgrade to 1.16.4, thanks! it worked for me.\\nNumpy version -  1.19.5, It worked for me. Thank you @raghavendragaleppa, I was working with tabular MNIST data !!\\none possible solution that worked for me was,\\nx_train.reset_index(drop=True,inplace=True)\\nx_test.reset_index(drop=True,inplace=True)\\ny_train.reset_index(drop=True,inplace=True)\\ny_test.reset_index(drop=True,inplace=True)\\nhope it helps for those using TABULAR dataset, iam trying to run a simple dqn code for cartpole environment in my computer.                                                        This is my code updated as you said;\\n    env = gym.make('CartPole-v1')\\n    q = Qnet()\\n    q_target = Qnet()\\n    q_target.load_state_dict(q.state_dict())\\n    memory = ReplayBuffer()\\n\\n    print_interval = 20\\n    score = 0.0  \\n    optimizer = optim.Adam(q.parameters(), lr=learning_rate)\\n\\n    for n_epi in range(10000):\\n        epsilon = max(0.01, 0.08 - 0.01*(n_epi/200)) #Linear annealing from 8% to 1%\\n        s = env.reset()\\n        done = False\\n        while not done:\\n            **a = q.sample_action(torch.from_numpy(np.asarray(s)).float(), epsilon)**      \\n            s_prime, r, done, info = env.step(a)\\n            done_mask = 0.0 if done else 1.0\\n            memory.put((s,a,r/100.0,s_prime, done_mask))\\n            s = s_prime\\n\\nbut iam getting the following error again where everything is fine\\nTraceback (most recent call last):\\nFile “d:\\college\\final yr\\project\\rl-series\\dqn\\simpledqn.py”, line 114, in \\nmain()\\nFile “d:\\college\\final yr\\project\\rl-series\\dqn\\simpledqn.py”, line 93, in main\\na = q.sample_action(torch.from_numpy(np.asarray(s)), epsilon)\\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part., Thanks! This solved my issue., I think this problem may arise from torch.from_numpy(array)'s mismatching with numpy version or dtype,and use other way of generating a tensor from numpy is a solution.]  \n",
       "1  [Are you seeing the same message, if you remove the multiprocessing code (I assume this is triggering it)?, Sorry for my late response and thank you for the reply!\\nI pinned the trigger of this warning. It happens if I set num_workers > 0 in torch.utils.data.DataLoader, instead of being caused by nn.DataParallel().\\nAny idea how to fix it? Is it probably due to that I set torch.multiprocessing.set_start_method('spawn', force=True)?, I have issued the same problem when setting num of workers to more then 0. @ptrblck, any solution ?, Unfortunately, I don’t have suggestions, as I don’t fully understand the use case of using torch.multiprocessing as well as multiple workers (which itself will use multiple processes), so could you explain the use case a bit more?, Hi @ptrblck, I came across the same issue and was intrigued by your remark:\\n\\n\\n\\n ptrblck:\\n\\nI don’t fully understand the use case of using torch.multiprocessing as well as multiple workers\\n\\n\\nFor one, isn’t it good to be able to process/load the data using a separate process, apart from the training process(es), in order to not tax them with extra processing load? Further, although it’s not my use case, loading the data might involve some heavy preprocessing, warranting even more than one data loader workers per training process; e.g. in the case in of some vision applications.\\nMaybe you have a completely different idea about this and give us your insight in to this topic.\\nThanks in advance., I totally agree with you and also think that multiple processes by themselves are useful, should be used for the data loading and process, and would yield a speedup in the overall training pipeline.\\nThis can be easily achieved with the num_workers argument of the DataLoader.\\nMy comment might not have been clear enough, but I was wondering about the use case to use the multiprocessing package manually in the training script as well as multiple workers (which will again spawn multiple processes, so you would end up with a “nested” multiprocessing workload), as I would imagine that using the simpler approach of setting num_workers>=1 should already do the job., Ah, ok, sorry, I didn’t notice the part about using the multiprocessing package separately. I think this is because I had the same issue just using DDP and Dataloaders with num_workers > 0. I get these errors just before my script exits; I already am a good citizen by using dist.barrier() to wait for all training processes to complete before exiting.\\nWhen I set the num_workers to zero the script exits smoothly without any errors. In the past I have often used multiple DataLoader workers in a DDP context and never had this issue. I’m wondering if this is something that sneaked in to a recent Pytorch release or is related to recent a CUDA version?\\nMy setup:\\n| NVIDIA-SMI 470.86 Driver Version: 470.86 CUDA Version: 11.4     |\\n\\n$ pip show torch\\nName: torch\\nVersion: 1.10.0\\n\\nThis is on a 4x V100 machine with Ubuntu.\\nIt might also be in my script of course., Ok, I dove a bit more in to this, and found the issue. In this particular instance I am using a model library where the author unfortunately had added the batch collate function as a method to the model class. Because of this the model self is also transported to the DataLoader workers.\\nWhen the training scripts exits the DataLoader worker processes are killed too, without properly dealing with the Tensors that are copied to the worker.\\nI refactored all the batch collating code out of the model class and thus made it independent of the self of the model instance. This resolved the issue, exiting the script is very smooth now!\\nSo, if anyone gets this error, it could be because your are copying the model over to the DataLoader workers without knowing it., Hi @visionscaper, I’m encountering the same issue. I’m currently using pytorch lightning to write my model. When I set the num_worker > 0 in the dataloader, the warning will occur. I’m a beginner in pytorch. Could you give me some example that how did you refactor your batch collating code out of model class? I don’t know how to do it., Hi @sjtuhl, if you have a similar issue to mine, somehow your model is linked to your dataset, collate_fn or other object given to a DataLoader. Because of this, when you set num_worker > 0, the model is copied to the DataLoader workers. For instance, if your dataset is a property of your model class instance (which is just bad design), not only your dataset is copied to the workers, but everything it is “attached” to as well.\\nI hope this makes sense to you. I can’t really help you without inspecting your code., Hi @visionscaper, I have the same issue as you. My data collate fn is written inside the dataset model. There are some tensors my collate_fn need, stored in the dataset model. I wonder if there is a way to avoid moving the collate_fn out and escape the error?, This warning is caused by tensors (or other objects) that are not being properly cleaned up (released) on the CUDA device before the process they belonged to was terminated.\\nAs it was for me in my case, and seems to be the case for mostly everyone else, the culprit behind this warning has to do with moving objects to, or owning objects on, the CUDA device from inside of one of the DataLoader worker processes, and the worker process being terminated before the  objects are released from CUDA.\\nMoving tensors to CUDA inside a collate_fn that is passed to a DataLoader where num_workers > 0 - which just means that a child process will be created for each worker - is an example of this, and is exactly what I was doing. In my training loop then, after all the training samples were iterated through, my DataLoader worker processes would be terminated and I would get this warning.\\nAs tempting as it is to move batches to CUDA inside the collate_fn, and though it may even provide some performance gains, the potential for a memory leak or some other resource management issue along with the annoying warning made me rethink my strategy. I ended up just relocating this logic to the first line in my training loop (on CPU - main process) where I move each batch to CUDA before my forward pass which I think is generally recommended anyway - never looked back since.\\nAlternatively, if you really wanted to, you could keep whatever objects you want on the CUDA device inside your DataLoader worker processes if you set persistent_workers=True in your DataLoader constructor and not encounter this warning until your DataLoader is entirely deallocated. You may encounter other issues though like running out of memory on the GPU, but I think for some use cases, maybe doing this could be beneficial.\\nHope this helps.]  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [Could you post a minimal and executable code snippet reproducing the issue?, Thanks for your response. Here are two scripts, please save them as script_1.py and script_2.py in the working directory. For this experiment, I’m using a model from huggingface, but the results are similar with my own segmentation model (nnU-Net).\\n# Save this as script_1.py\\n\\nimport torch\\nimport numpy as np\\nimport random\\nimport requests\\nimport pickle\\nimport argparse\\n\\nif __name__ == '__main__':\\n\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument(\"--result_filename\", help=\"location to save the result prediction\")\\n\\n    args = parser.parse_args()\\n    \\n    # Set the seed for all random number generators\\n    seed = 42\\n    torch.manual_seed(seed)\\n    random.seed(seed)\\n    np.random.seed(seed)\\n    torch.cuda.manual_seed(seed)\\n    torch.cuda.manual_seed_all(seed)\\n\\n    # Ensure deterministic behavior\\n    torch.backends.cudnn.deterministic = True\\n    torch.backends.cudnn.benchmark = False\\n\\n    # Set CUBLAS workspace config to ensure deterministic cuBLAS\\n    import os\\n    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\\n\\n    torch.use_deterministic_algorithms(True)\\n    torch.set_num_threads(1)\\n\\n    # Download the file\\n    url = 'https://huggingface.co/spaces/Xajimel/Practica3/resolve/main/unet.pth'\\n    response = requests.get(url)\\n    with open('model.pt', 'wb') as f:\\n        f.write(response.content)\\n\\n    model = torch.jit.load('model.pt')\\n    model = model.to(torch.device('cuda:0'))\\n    model = model.half()\\n\\n    # Create a random array\\n    torch.manual_seed(0)\\n    random_arr = torch.randn(1, 3, 224, 224, dtype = torch.half).to(torch.device('cuda:0'))\\n    pred = model(random_arr).to(torch.device('cpu')).detach().numpy()\\n\\n    with open(args.result_filename, 'wb') as f:\\n        pickle.dump(pred, f)\\n\\n# Save this as script_2.py\\n\\nimport pickle\\nimport numpy as np\\n\\nwith open('pred1.pkl', 'rb') as f:\\n    a = pickle.load(f)\\n\\nwith open('pred2.pkl', 'rb') as f:\\n    b = pickle.load(f)\\n\\nprint('Length of a: ', len(a))\\nprint('Length of b: ', len(b))\\n\\nprint('Shape of first element in a: ', a[0].shape)\\nprint('Shape of first element in b: ', b[0].shape)\\n\\ndiff = a[0] - b[0]\\n\\nprint('Min diff: ', np.min(diff))\\nprint('Max diff: ', np.max(diff))\\n\\nRun this with the following commands.\\npython script_1.py --result_filename pred1.pkl\\npython script_1.py --result_filename pred2.pkl\\npython script_2.py\\n\\nSomething I found interesting was that if I change the url in script_1.py to a different model (say this one), I see no differences in the prediction.\\nI wonder if the issue then is non-determinism in some layers in the nnU-Net model or the way I’m saving the model. This is how I save the model.\\nself.network = self.network.to(self.device)\\nself.network.eval()\\ntorch.use_deterministic_algorithms(True)\\ntraced_model = torch.jit.trace(self.network, torch.randn(1, 1, 224, 224, 224).to(self.device))\\ntorch.jit.save(traced_model, 'model.pt')\\n\\nLet me know what you think or if you need some more info. Thanks!, I cannot reproduce the issue and see:\\nLength of a:  1\\nLength of b:  1\\nShape of first element in a:  (5, 224, 224)\\nShape of first element in b:  (5, 224, 224)\\nMin diff:  0.0\\nMax diff:  0.0, This is what I see. I’m on torch 2.3.0+cu121 if that helps.\\nLength of a:  1\\nLength of b:  1\\nShape of first element in a:  (5, 224, 224)\\nShape of first element in b:  (5, 224, 224)\\nMin diff:  -0.01563\\nMax diff:  0.01172, @ptrblck On the machine that I was initially testing on, I see the issue on torch 2.3.0+cu121 and torch 2.4.0+cu121. On another machine, I don’t see the issue in either versions. These machines have different GPUs (earlier: A40, now: RTX 3050 Ti).\\nCould the underlying GPU make a difference?]  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         []  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [benoriol:\\n\\nIf I then add some operation that downloads something to cpu memory such as l = loss.item() after the optimizer step, I get something like this:\\n\\n\\nThis is expected since the item() call is synchronizing the GPU.\\n\\n\\n\\n benoriol:\\n\\nI am a bit confused by this behaviour. My hypothesis is that my profiler might be measuring the async python function calls and not the actual cuda kernels.\\n\\n\\nYes, this seems to be the case and I would expect to see different time lines: one for the host and another one for the device.\\nI’m not familiar with the native PyTorch profiler visualization as I am using Nsight Systems for profiling. You could check this post for instructions on how to use nsys., That makes sense, thanks.\\nOne more question, is there a limit to the number of async python calls that pytorch can do without waiting for the actual computation to be done in the GPU? It seems that it is doing multiple faster non-blocking calls to training steps (#16 and #17) before it starts to take longer in step #18, I assume waiting for GPU to finish the previous ones. In general, what is a good resource where I can learn more about how Pytorch works under the hood?\\nIn any case I will switch to nsys profiler, seems like a much better option. Thanks a lot., benoriol:\\n\\nOne more question, is there a limit to the number of async python calls that pytorch can do without waiting for the actual computation to be done in the GPU?\\n\\n\\nYes, the queue handling the CUDA kernel launches is limited and the host will be blocked if the queue is saturated.]  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the file as newline-delimited JSON\n",
    "df = pd.read_json('/Users/moutasemhome/Human-vs.-Synthetic-Datasets-Advancing-Niche-Model-Training-for-qa/data/forum_qas_v3_append.json', lines=True)\n",
    "\n",
    "# Display the dataframe\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some questions with no ansswers (empty list). Let's filter them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>all_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>https://discuss.pytorch.org/t/why-do-i-get-typeerror-expected-np-ndarray-got-numpy-ndarray-when-i-use-torch-from-numpy-function/37525</td>\n",
       "      <td>Why do I get “TypeError: expected np.ndarray (got numpy.ndarray)”  when I use torch.from_numpy() function? Isn’t np.ndarray equivalent to numpy.ndarray? Also, there doesn’t seem to be any np.ndarray type, but only numpy.ndarray type.\\nTraceback (most recent call last): File \"test_opencv.py\", line 31, in &lt;module&gt; bounding_boxes, landmarks = detect_faces(img, pnet, rnet, onet) File \"/home/xxx/git/project/src/detector.py\", line 67, in detect_faces boxes = run_first_stage(image, pnet, scale=s, threshold=thresholds[0]) File \"/home/xxx/git/project/src/first_stage.py\", line 73, in run_first_stage img = torch.from_numpy(img).unsqueeze(0).permute(0,3,1,2).cuda().float() TypeError: expected np.ndarray (got numpy.ndarray)</td>\n",
       "      <td>[Can you share some debugging info like printing type(img) and img.dtype I wrote the same line of code and it worked for me.\\nThere has to be some bug in the data loading process of the image., Hello It seems you are getting the error because the argument to from_numpy function is a single value rather than array.\\nIn numpy, there is difference between np.array(1) and np.array([1]) and both are completely different data types.\\nTry torch.from_numpy(np.asarray(x))., Hello, I have encountered the same problem. Do you have any solutions?Thank you, Try\\ntorch.as_tensor(np.array(pil_img).astype('float'))\\nIt worked for me., Have you fix this problem? I encounter this problem too…, Could you post a minimal code snippet to reproduce this error?, I found it is because of the version of numpy…\\n\\n\\n\\n信工 刘蓬博\\n邮箱：pengbo18555@163.com\\n签名由 网易邮箱大师 定制, It’s also happening to me on numpy 1.17.4, my own solution is to downgrade to 1.16.4, thanks! it worked for me.\\nNumpy version -  1.19.5, It worked for me. Thank you @raghavendragaleppa, I was working with tabular MNIST data !!\\none possible solution that worked for me was,\\nx_train.reset_index(drop=True,inplace=True)\\nx_test.reset_index(drop=True,inplace=True)\\ny_train.reset_index(drop=True,inplace=True)\\ny_test.reset_index(drop=True,inplace=True)\\nhope it helps for those using TABULAR dataset, iam trying to run a simple dqn code for cartpole environment in my computer.                                                        This is my code updated as you said;\\n    env = gym.make('CartPole-v1')\\n    q = Qnet()\\n    q_target = Qnet()\\n    q_target.load_state_dict(q.state_dict())\\n    memory = ReplayBuffer()\\n\\n    print_interval = 20\\n    score = 0.0  \\n    optimizer = optim.Adam(q.parameters(), lr=learning_rate)\\n\\n    for n_epi in range(10000):\\n        epsilon = max(0.01, 0.08 - 0.01*(n_epi/200)) #Linear annealing from 8% to 1%\\n        s = env.reset()\\n        done = False\\n        while not done:\\n            **a = q.sample_action(torch.from_numpy(np.asarray(s)).float(), epsilon)**      \\n            s_prime, r, done, info = env.step(a)\\n            done_mask = 0.0 if done else 1.0\\n            memory.put((s,a,r/100.0,s_prime, done_mask))\\n            s = s_prime\\n\\nbut iam getting the following error again where everything is fine\\nTraceback (most recent call last):\\nFile “d:\\college\\final yr\\project\\rl-series\\dqn\\simpledqn.py”, line 114, in \\nmain()\\nFile “d:\\college\\final yr\\project\\rl-series\\dqn\\simpledqn.py”, line 93, in main\\na = q.sample_action(torch.from_numpy(np.asarray(s)), epsilon)\\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part., Thanks! This solved my issue., I think this problem may arise from torch.from_numpy(array)'s mismatching with numpy version or dtype,and use other way of generating a tensor from numpy is a solution.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>https://discuss.pytorch.org/t/w-cudaipctypes-cpp-22-producer-process-has-been-terminated-before-all-shared-cuda-tensors-released-see-note-sharing-cuda-tensors/124445</td>\n",
       "      <td>I got this warning at the end of each epoch when using multiple GPUs:\\n[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\\nBut it doesn’t seem to affect the training since the result is as good as it is.\\nBut I would still like to know what the probable cause is and how to solve it  \\nI simply use: model = torch.nn.DataParallel(model) to enable multi-GPUs.\\nBesides, I also added torch.multiprocessing.set_start_method('spawn', force=True) in my code. Don’t know whether it has any effect on this.\\nThank you for the answer in advance.</td>\n",
       "      <td>[Are you seeing the same message, if you remove the multiprocessing code (I assume this is triggering it)?, Sorry for my late response and thank you for the reply!\\nI pinned the trigger of this warning. It happens if I set num_workers &gt; 0 in torch.utils.data.DataLoader, instead of being caused by nn.DataParallel().\\nAny idea how to fix it? Is it probably due to that I set torch.multiprocessing.set_start_method('spawn', force=True)?, I have issued the same problem when setting num of workers to more then 0. @ptrblck, any solution ?, Unfortunately, I don’t have suggestions, as I don’t fully understand the use case of using torch.multiprocessing as well as multiple workers (which itself will use multiple processes), so could you explain the use case a bit more?, Hi @ptrblck, I came across the same issue and was intrigued by your remark:\\n\\n\\n\\n ptrblck:\\n\\nI don’t fully understand the use case of using torch.multiprocessing as well as multiple workers\\n\\n\\nFor one, isn’t it good to be able to process/load the data using a separate process, apart from the training process(es), in order to not tax them with extra processing load? Further, although it’s not my use case, loading the data might involve some heavy preprocessing, warranting even more than one data loader workers per training process; e.g. in the case in of some vision applications.\\nMaybe you have a completely different idea about this and give us your insight in to this topic.\\nThanks in advance., I totally agree with you and also think that multiple processes by themselves are useful, should be used for the data loading and process, and would yield a speedup in the overall training pipeline.\\nThis can be easily achieved with the num_workers argument of the DataLoader.\\nMy comment might not have been clear enough, but I was wondering about the use case to use the multiprocessing package manually in the training script as well as multiple workers (which will again spawn multiple processes, so you would end up with a “nested” multiprocessing workload), as I would imagine that using the simpler approach of setting num_workers&gt;=1 should already do the job., Ah, ok, sorry, I didn’t notice the part about using the multiprocessing package separately. I think this is because I had the same issue just using DDP and Dataloaders with num_workers &gt; 0. I get these errors just before my script exits; I already am a good citizen by using dist.barrier() to wait for all training processes to complete before exiting.\\nWhen I set the num_workers to zero the script exits smoothly without any errors. In the past I have often used multiple DataLoader workers in a DDP context and never had this issue. I’m wondering if this is something that sneaked in to a recent Pytorch release or is related to recent a CUDA version?\\nMy setup:\\n| NVIDIA-SMI 470.86 Driver Version: 470.86 CUDA Version: 11.4     |\\n\\n$ pip show torch\\nName: torch\\nVersion: 1.10.0\\n\\nThis is on a 4x V100 machine with Ubuntu.\\nIt might also be in my script of course., Ok, I dove a bit more in to this, and found the issue. In this particular instance I am using a model library where the author unfortunately had added the batch collate function as a method to the model class. Because of this the model self is also transported to the DataLoader workers.\\nWhen the training scripts exits the DataLoader worker processes are killed too, without properly dealing with the Tensors that are copied to the worker.\\nI refactored all the batch collating code out of the model class and thus made it independent of the self of the model instance. This resolved the issue, exiting the script is very smooth now!\\nSo, if anyone gets this error, it could be because your are copying the model over to the DataLoader workers without knowing it., Hi @visionscaper, I’m encountering the same issue. I’m currently using pytorch lightning to write my model. When I set the num_worker &gt; 0 in the dataloader, the warning will occur. I’m a beginner in pytorch. Could you give me some example that how did you refactor your batch collating code out of model class? I don’t know how to do it., Hi @sjtuhl, if you have a similar issue to mine, somehow your model is linked to your dataset, collate_fn or other object given to a DataLoader. Because of this, when you set num_worker &gt; 0, the model is copied to the DataLoader workers. For instance, if your dataset is a property of your model class instance (which is just bad design), not only your dataset is copied to the workers, but everything it is “attached” to as well.\\nI hope this makes sense to you. I can’t really help you without inspecting your code., Hi @visionscaper, I have the same issue as you. My data collate fn is written inside the dataset model. There are some tensors my collate_fn need, stored in the dataset model. I wonder if there is a way to avoid moving the collate_fn out and escape the error?, This warning is caused by tensors (or other objects) that are not being properly cleaned up (released) on the CUDA device before the process they belonged to was terminated.\\nAs it was for me in my case, and seems to be the case for mostly everyone else, the culprit behind this warning has to do with moving objects to, or owning objects on, the CUDA device from inside of one of the DataLoader worker processes, and the worker process being terminated before the  objects are released from CUDA.\\nMoving tensors to CUDA inside a collate_fn that is passed to a DataLoader where num_workers &gt; 0 - which just means that a child process will be created for each worker - is an example of this, and is exactly what I was doing. In my training loop then, after all the training samples were iterated through, my DataLoader worker processes would be terminated and I would get this warning.\\nAs tempting as it is to move batches to CUDA inside the collate_fn, and though it may even provide some performance gains, the potential for a memory leak or some other resource management issue along with the annoying warning made me rethink my strategy. I ended up just relocating this logic to the first line in my training loop (on CPU - main process) where I move each batch to CUDA before my forward pass which I think is generally recommended anyway - never looked back since.\\nAlternatively, if you really wanted to, you could keep whatever objects you want on the CUDA device inside your DataLoader worker processes if you set persistent_workers=True in your DataLoader constructor and not encounter this warning until your DataLoader is entirely deallocated. You may encounter other issues though like running out of memory on the GPU, but I think for some use cases, maybe doing this could be beneficial.\\nHope this helps.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>https://discuss.pytorch.org/t/determinism-in-inference/208033</td>\n",
       "      <td>I have the following code snippet. When I run the script consecutively, I get different results in prediction. Is there a setting I’m missing?\\nimport torch\\nimport numpy as np\\nimport random\\n\\n# Set the seed for all random number generators\\nseed = 42\\ntorch.manual_seed(seed)\\nrandom.seed(seed)\\nnp.random.seed(seed)\\ntorch.cuda.manual_seed(seed)\\ntorch.cuda.manual_seed_all(seed)\\n\\n# Ensure deterministic behavior\\ntorch.backends.cudnn.deterministic = True\\ntorch.backends.cudnn.benchmark = False\\n\\n# Set CUBLAS workspace config to ensure deterministic cuBLAS\\nimport os\\nos.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\\n\\ntorch.use_deterministic_algorithms(True)\\ntorch.set_num_threads(1)\\n\\n# Load the model\\nmodel = torch.jit.load('test.pt')\\nmodel = model.to(torch.device('cuda:0'))\\nmodel = model.half()\\n\\n# Create a random array\\ntorch.manual_seed(0)\\nrandom_arr = torch.randn(1,1,224, 224, 224, dtype = torch.half).to(torch.device('cuda:0'))\\npred = model(random_arr).to(torch.device('cpu')).detach().numpy()\\n\\nThe pred variable is different in each run, max. difference is about 3e-2. Any help would be appreciated. Thanks!</td>\n",
       "      <td>[Could you post a minimal and executable code snippet reproducing the issue?, Thanks for your response. Here are two scripts, please save them as script_1.py and script_2.py in the working directory. For this experiment, I’m using a model from huggingface, but the results are similar with my own segmentation model (nnU-Net).\\n# Save this as script_1.py\\n\\nimport torch\\nimport numpy as np\\nimport random\\nimport requests\\nimport pickle\\nimport argparse\\n\\nif __name__ == '__main__':\\n\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument(\"--result_filename\", help=\"location to save the result prediction\")\\n\\n    args = parser.parse_args()\\n    \\n    # Set the seed for all random number generators\\n    seed = 42\\n    torch.manual_seed(seed)\\n    random.seed(seed)\\n    np.random.seed(seed)\\n    torch.cuda.manual_seed(seed)\\n    torch.cuda.manual_seed_all(seed)\\n\\n    # Ensure deterministic behavior\\n    torch.backends.cudnn.deterministic = True\\n    torch.backends.cudnn.benchmark = False\\n\\n    # Set CUBLAS workspace config to ensure deterministic cuBLAS\\n    import os\\n    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\\n\\n    torch.use_deterministic_algorithms(True)\\n    torch.set_num_threads(1)\\n\\n    # Download the file\\n    url = 'https://huggingface.co/spaces/Xajimel/Practica3/resolve/main/unet.pth'\\n    response = requests.get(url)\\n    with open('model.pt', 'wb') as f:\\n        f.write(response.content)\\n\\n    model = torch.jit.load('model.pt')\\n    model = model.to(torch.device('cuda:0'))\\n    model = model.half()\\n\\n    # Create a random array\\n    torch.manual_seed(0)\\n    random_arr = torch.randn(1, 3, 224, 224, dtype = torch.half).to(torch.device('cuda:0'))\\n    pred = model(random_arr).to(torch.device('cpu')).detach().numpy()\\n\\n    with open(args.result_filename, 'wb') as f:\\n        pickle.dump(pred, f)\\n\\n# Save this as script_2.py\\n\\nimport pickle\\nimport numpy as np\\n\\nwith open('pred1.pkl', 'rb') as f:\\n    a = pickle.load(f)\\n\\nwith open('pred2.pkl', 'rb') as f:\\n    b = pickle.load(f)\\n\\nprint('Length of a: ', len(a))\\nprint('Length of b: ', len(b))\\n\\nprint('Shape of first element in a: ', a[0].shape)\\nprint('Shape of first element in b: ', b[0].shape)\\n\\ndiff = a[0] - b[0]\\n\\nprint('Min diff: ', np.min(diff))\\nprint('Max diff: ', np.max(diff))\\n\\nRun this with the following commands.\\npython script_1.py --result_filename pred1.pkl\\npython script_1.py --result_filename pred2.pkl\\npython script_2.py\\n\\nSomething I found interesting was that if I change the url in script_1.py to a different model (say this one), I see no differences in the prediction.\\nI wonder if the issue then is non-determinism in some layers in the nnU-Net model or the way I’m saving the model. This is how I save the model.\\nself.network = self.network.to(self.device)\\nself.network.eval()\\ntorch.use_deterministic_algorithms(True)\\ntraced_model = torch.jit.trace(self.network, torch.randn(1, 1, 224, 224, 224).to(self.device))\\ntorch.jit.save(traced_model, 'model.pt')\\n\\nLet me know what you think or if you need some more info. Thanks!, I cannot reproduce the issue and see:\\nLength of a:  1\\nLength of b:  1\\nShape of first element in a:  (5, 224, 224)\\nShape of first element in b:  (5, 224, 224)\\nMin diff:  0.0\\nMax diff:  0.0, This is what I see. I’m on torch 2.3.0+cu121 if that helps.\\nLength of a:  1\\nLength of b:  1\\nShape of first element in a:  (5, 224, 224)\\nShape of first element in b:  (5, 224, 224)\\nMin diff:  -0.01563\\nMax diff:  0.01172, @ptrblck On the machine that I was initially testing on, I see the issue on torch 2.3.0+cu121 and torch 2.4.0+cu121. On another machine, I don’t see the issue in either versions. These machines have different GPUs (earlier: A40, now: RTX 3050 Ti).\\nCould the underlying GPU make a difference?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>https://discuss.pytorch.org/t/updating-adam-optimizer-after-modifying-model-architecture/208101</td>\n",
       "      <td>import torch.nn as nn\\nimport torch\\n\\nclass Foo(nn.Module):\\n    def __init__(self, input_size=20, output_size=100):\\n        super().__init__()\\n        self.input_size = input_size\\n        self.output_size = output_size\\n\\n        self.fc0 = nn.Linear(self.input_size, 30)\\n        self.fc1 = nn.Linear(30, 40)\\n        self.fc_out = nn.Linear(40, self.output_size)\\n\\n    def increment_output_size(self, copy_idx: int):\\n        old_output_size = self.output_size\\n        old_fc_out = self.fc_out\\n\\n        self.output_size += 1\\n        self.fc_out = nn.Linear(40, self.output_size)\\n        with torch.no_grad():\\n            self.fc_out.weight.data[:old_output_size] = old_fc_out.weight.data\\n            self.fc_out.weight.data[-1] = old_fc_out.weight.data[copy_idx].clone()\\n            self.fc_out.bias.data[:old_output_size] = old_fc_out.bias.data\\n            self.fc_out.bias.data[-1] = old_fc_out.bias.data[copy_idx].clone()\\n\\n\\nif __name__ == \"__main__\":\\n    # SETUP MODEL AND OPTIMIZER\\n    model = Foo()\\n    optimizer = torch.optim.Adam(model.parameters())\\n\\n    # DO SOME TRAINING HERE (Adam optimizer will hold state stat for each parameter)\\n    # ...\\n\\n    # MODIFY MODEL\\n    model.increment_output_size(copy_idx=25)\\n\\n    # UPDATE OPTIMIZER\\n    #  1. For parameters (weights/bias) of model.fc0 and model.fc1, the state should be retained.\\n    #  2. For parameter fc_out, which is modified:\\n    #     a. for model.fc_out.weight/bias[:100], preserve the corresponding states in Adam\\n    #     b. for model.fc_out.weight/bias[101], clone the state corresponding to model.fc_out.weight[25]\\n\\n    # DO SOME MORE TRAINING HERE\\n    # ...\\n\\n    print(\"Done\")\\n\\nThe code above attempts to train a model that, throughout the training process, may dynamically modify its self.fc_out module to accommodate for increase in the number of classes. I want it so that the existing Adam optimizer can adaptively update its internal state in accordance to the model modification. This means both updating the relevant items in self.updater.optimizer.param_groups[0][\"params\"] and self.updater.optimizer.state (and other stuff, if necessary).\\nHow can I do this? Specifically:\\n\\nHow can I index the optimizer fields/keys relevant to the self.fc_out?\\nHow do I replace the relevant optimizer params and states? Is it sufficient to do self.updater.optimizer.param_groups[0][\"params\"][index_of_fc_out_weight] = model.fc_out.weight and self.updater.optimizer.state[index_of_fc_out_weight] = new_fc_out_state?\\nAre there any other fields or under-the-hood mechanisms that I need to be aware of?\\n\\nAny help is appreciated.</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>https://discuss.pytorch.org/t/weird-pytorch-profiler-output/208078</td>\n",
       "      <td>Hello,\\nI am profiling my training code and I’m struggling to understand the output. The different steps seem to be taking different amount of time and I am not sure why.\\nimage3082×1044 378 KB\\nA simplified version of my code would be:\\nwith profiler.profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], ...) as p:\\n    for x, y in training_dataloader:\\n        p.step()\\n        out = model(x)\\n        loss = loss_fn(out,y)\\n        loss.backward()\\n        optim.step()\\n        optim.zero_grad()\\n\\nScheduler is set to skip_first=10, wait=5, warmup=1, active=5, repeat=1\\nIf I then add some operation that downloads something to cpu memory such as l = loss.item() after the optimizer step, I get something like this:\\nimage3048×1050 292 KB\\nIn both scenarios the average train step is the same even though each profiler step seems to vary in time in the first case.\\nI am a bit confused by this behaviour. My hypothesis is that my profiler might be measuring the async python function calls and not the actual cuda kernels. But isn’t the point of the profiler to measure the cuda kernel time? I am interested in analysing how long does my CPU and GPU take in each part of the code, and I guess here I am just seeing the CPU?\\nIf I go down below in the GPU thread part of the profiler, I get this, which I don’t understand or is giving me too little information about how long is spent in each kernel by the gpu.\\nimage4106×798 183 KB\\nNote that this screenshot is taken for the first example where i do NOT add l = loss.item() and all the different steps are taking different time in cpu time. Yet in the GPU thread they seem to be taking the same amount of time.\\nI would appreciate any insights on why this is happening or if my intuitions are correct and what is the best way to measure how long is my GPU spending in each kernel.\\nI am using a 4090 GPU and the model is a simple UNet with 128x128 image input.\\nThanks,\\nBenet</td>\n",
       "      <td>[benoriol:\\n\\nIf I then add some operation that downloads something to cpu memory such as l = loss.item() after the optimizer step, I get something like this:\\n\\n\\nThis is expected since the item() call is synchronizing the GPU.\\n\\n\\n\\n benoriol:\\n\\nI am a bit confused by this behaviour. My hypothesis is that my profiler might be measuring the async python function calls and not the actual cuda kernels.\\n\\n\\nYes, this seems to be the case and I would expect to see different time lines: one for the host and another one for the device.\\nI’m not familiar with the native PyTorch profiler visualization as I am using Nsight Systems for profiling. You could check this post for instructions on how to use nsys., That makes sense, thanks.\\nOne more question, is there a limit to the number of async python calls that pytorch can do without waiting for the actual computation to be done in the GPU? It seems that it is doing multiple faster non-blocking calls to training steps (#16 and #17) before it starts to take longer in step #18, I assume waiting for GPU to finish the previous ones. In general, what is a good resource where I can learn more about how Pytorch works under the hood?\\nIn any case I will switch to nsys profiler, seems like a much better option. Thanks a lot., benoriol:\\n\\nOne more question, is there a limit to the number of async python calls that pytorch can do without waiting for the actual computation to be done in the GPU?\\n\\n\\nYes, the queue handling the CUDA kernel launches is limited and the host will be blocked if the queue is saturated.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30629</th>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>https://discuss.pytorch.org/t/how-to-check-if-torch-uses-cudnn/21933</td>\n",
       "      <td>So i just used packer to bake my own images for GCE and ran into the following situation.\\nInstalled CUDA 9.0 and everything worked fine, I could train my models on the GPU.\\nAfte a while I noticed I forgot to install cuDNN, however it seems that pytorch does not complain about this. On an image with only CUDA installed, if I run\\ntorch.backends.cudnn.version() I get 7102 and torch.backends.cudnn.enabled == True\\nWhen I did install cuDNN from https://developer.nvidia.com/cudnn, everything still worked fine, I still got the same outputs for the two command above, but I didn’t get significant speedups.\\nDoes this mean if one installs only CUDA and PyTorch, cuDNN also gets magically installed? Or is there a way how to check if pytorch is really using the speedups promised from cuDNN?\\nAny advice? Thanks</td>\n",
       "      <td>[How did you install PyTorch?\\nThe binaries are shipped with CUDA and cuDNN already., I used a script like this, to install CUDA, cuDNN and Python and then used pipenv install torch to install PyTorch. The image was based on Google Clouds “ubuntu-1604-lts”. But even if I comment out the line that installs cuDNN nothing seems to change for my PyTorch installation?\\n# install CUDA\\necho \"Checking for CUDA and installing.\"\\n# Check for CUDA and try to install.\\nif ! dpkg-query -W cuda-9-0; then\\n  # The 16.04 installer works with 16.10.\\n  wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_9.0.176-1_amd64.deb\\n  sudo apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/7fa2af80.pub\\n  sudo dpkg -i cuda-repo-ubuntu1604_9.0.176-1_amd64.deb\\n  sudo apt-get update\\n  sudo apt-get install cuda-9-0 -y\\nfi\\n\\n# install cuDNN\\nsudo dpkg -i /tmp/libcudnn7_7.1.4.18-1+cuda9.0_amd64.deb\\n\\n\\n# install python\\nsudo add-apt-repository ppa:deadsnakes/ppa\\nsudo apt-get update\\nsudo apt-get install -y python3.6\\nsudo apt-get install -y python3-pip\\n\\n# install pipenv\\nsudo pip3 install pipenv, Ok, I just found an answer by soumith on another thread:\\n“if you want to use pytorch with an NVIDIA GPU, all you need to do is install pytorch binaries and start using it. We ship with everything in-built (pytorch binaries include CUDA, CuDNN, NCCL, MKL, etc.).”\\nso that means the whole installing CUDA and cuDNN on Ubuntu shenanigans are actually not necessary at all?! That would also explain my confusion, why I get the same time to train no matter if I install cudnn or not\\nsorry for the confusion, Yes, you just need to install the NVIDIA drivers and the binaries will come with the other libs.\\nIf you want to build from source, you would need to install CUDA, cuDNN etc., Could you check your LD_LIBRARY_PATH to see if you have some libs linking against your own libcudart as described in this issue?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30630</th>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>https://discuss.pytorch.org/t/how-to-work-with-3d-torch-in-a-linear-forward-pass/32481</td>\n",
       "      <td>Hi everyone!\\nI saw several topics on how to feed a 3D tensor into a Neural Network but it’s not quite clear to me what’s happening.\\nI’m working with stock data and for each individual stock I have a 2 dimension torch containing several information (in columns) for each day. So, for each stock I have a matrix with features for column and days for rows and my NN works fine for a single stock. However, I’d like to apply the same operations for several stocks, thus yielding a 3d torch with the third dimension referring to each individual asset.\\nIf I reshape the data into a 2d torch (stacking the features) I think i’ll lose information when trying to predict a single outcome with the trained NN. I’ve also found some topics explaining how to pass a 3d tensor to a Linear pass, but I understand they will make the Linear regression layer by layer, whereas I’d like to minimize the error for the whole 3d tensor.\\nDo you have any thoughts on that that might help me out?\\nthanks!</td>\n",
       "      <td>[Would you like to use the same linear layers for both inputs?\\nIf so, you could just create a tensor of the shape [batch_dim, nb_stocks, in_features] and the layers will be applied on each nb_stock dimension., I tried that, but it seems the output converges on the out layer. It is, instead of the output adjusting to the stock series, it returns a horizontal line. I’m not sure what the problem might be, Could you try to fit a very small data sample (e.g. just one or five samples) and see if your model correctly overfits on this small sample?\\nIf that’s not possible, there might be other problems in your code.\\nHowever, if that works, I would try to scale up the problem using a bit more samples and see, when the model training breaks. Maybe your model’s architecture is currently not suitable for the problem or your model has just not enough capacity.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30631</th>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>https://discuss.pytorch.org/t/nan-values-after-optim-step/9975</td>\n",
       "      <td>Hi,\\nI’m just getting some NaN in some module parameters (word embedding weights).\\nI just indentified that the NaN comes with the optim.step() instruction.\\nWhat could typically leads to this? (sharing code would be unpractical as there is quite a lot of things, hard to get an atomic reproducible example :/)\\nInterestingly enough, this problem only appears on some data (I’ve some toy data to test based on the PTB dataset with target = source; target = reversed source or a dataset with input=random integer sequence, target=sorted sequence)\\nThx\\n\\nmy model is made of 2-brnn lstm encoder with shared embedding, 2-lstm decoder with temporal attention over source and intra-decoder attention (as described in Paulus et al, (2017)).</td>\n",
       "      <td>[The problem was very task specific.\\nFor some reason I was not using part of a parameter (but only a slice of the matrix), which, I suppose, made it a NaN, I have the same issue as you.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30632</th>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>https://discuss.pytorch.org/t/difference-between-nn-upsample-and-nn-convtranspose2d/32653</td>\n",
       "      <td>Since for nn.Upsample, it’s possible to deal with 2D Tensor, so what’s the difference here between the upsample and the convtranspose2d. Thank you</td>\n",
       "      <td>[While nn.Upsample uses some interpolation technique, nn.ConvTranspose uses trainable filters to create your output (similar to vanilla conv layers)., Thank you for your information, can you explain the pros and cons of these two function.\\nIs the upsample recover more context information or the ConvTranspose?, Generally speaking, the ConvTranpose layer might learn some features as it’s using trainable parameters, while Upsample just interpolates.\\nThe former approach would thus have more parameters (more capacity) and might therefore overfit easier.\\nI can’t really tell which approach works better in which situation, as I’ve seen both methods used for certain use cases.\\nWhile it seems that ConvTranpose layers are preferred in GANs, I’ve seen some models using Upsample performed better for segmentation tasks. This is just my biased observation, so this is not a recommendation to choose one over the other.\\nYou should try both approaches and see, how your model performs., Thank you, that helps a lot.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30633</th>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>https://discuss.pytorch.org/t/loss-function-error/33065</td>\n",
       "      <td>when i use nn.CrossEntropyLoss to train a segmentation model.But it shows that 'lonly batches of spatial targets supported(non-empty 3D tensors)but got targets of size :[2,1,512,512]\\nthe output_size of the model is [2,2,512,512](batch_size = 2 and num_classes = 2]\\nThanks</td>\n",
       "      <td>[Have you tried squeezeing the targets to [2, 512, 512]?, Thank you very much.  When i squeeze ing the targets to  [2, 512, 512] ,it is work.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30634 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            category  \\\n",
       "0      Uncategorized   \n",
       "1      Uncategorized   \n",
       "2      Uncategorized   \n",
       "3      Uncategorized   \n",
       "4      Uncategorized   \n",
       "...              ...   \n",
       "30629  Uncategorized   \n",
       "30630  Uncategorized   \n",
       "30631  Uncategorized   \n",
       "30632  Uncategorized   \n",
       "30633  Uncategorized   \n",
       "\n",
       "                                                                                                                                                                       title  \\\n",
       "0                                      https://discuss.pytorch.org/t/why-do-i-get-typeerror-expected-np-ndarray-got-numpy-ndarray-when-i-use-torch-from-numpy-function/37525   \n",
       "1      https://discuss.pytorch.org/t/w-cudaipctypes-cpp-22-producer-process-has-been-terminated-before-all-shared-cuda-tensors-released-see-note-sharing-cuda-tensors/124445   \n",
       "2                                                                                                              https://discuss.pytorch.org/t/determinism-in-inference/208033   \n",
       "3                                                                            https://discuss.pytorch.org/t/updating-adam-optimizer-after-modifying-model-architecture/208101   \n",
       "4                                                                                                         https://discuss.pytorch.org/t/weird-pytorch-profiler-output/208078   \n",
       "...                                                                                                                                                                      ...   \n",
       "30629                                                                                                   https://discuss.pytorch.org/t/how-to-check-if-torch-uses-cudnn/21933   \n",
       "30630                                                                                 https://discuss.pytorch.org/t/how-to-work-with-3d-torch-in-a-linear-forward-pass/32481   \n",
       "30631                                                                                                         https://discuss.pytorch.org/t/nan-values-after-optim-step/9975   \n",
       "30632                                                                              https://discuss.pytorch.org/t/difference-between-nn-upsample-and-nn-convtranspose2d/32653   \n",
       "30633                                                                                                                https://discuss.pytorch.org/t/loss-function-error/33065   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             question  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Why do I get “TypeError: expected np.ndarray (got numpy.ndarray)”  when I use torch.from_numpy() function? Isn’t np.ndarray equivalent to numpy.ndarray? Also, there doesn’t seem to be any np.ndarray type, but only numpy.ndarray type.\\nTraceback (most recent call last): File \"test_opencv.py\", line 31, in <module> bounding_boxes, landmarks = detect_faces(img, pnet, rnet, onet) File \"/home/xxx/git/project/src/detector.py\", line 67, in detect_faces boxes = run_first_stage(image, pnet, scale=s, threshold=thresholds[0]) File \"/home/xxx/git/project/src/first_stage.py\", line 73, in run_first_stage img = torch.from_numpy(img).unsqueeze(0).permute(0,3,1,2).cuda().float() TypeError: expected np.ndarray (got numpy.ndarray)   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        I got this warning at the end of each epoch when using multiple GPUs:\\n[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\\nBut it doesn’t seem to affect the training since the result is as good as it is.\\nBut I would still like to know what the probable cause is and how to solve it  \\nI simply use: model = torch.nn.DataParallel(model) to enable multi-GPUs.\\nBesides, I also added torch.multiprocessing.set_start_method('spawn', force=True) in my code. Don’t know whether it has any effect on this.\\nThank you for the answer in advance.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               I have the following code snippet. When I run the script consecutively, I get different results in prediction. Is there a setting I’m missing?\\nimport torch\\nimport numpy as np\\nimport random\\n\\n# Set the seed for all random number generators\\nseed = 42\\ntorch.manual_seed(seed)\\nrandom.seed(seed)\\nnp.random.seed(seed)\\ntorch.cuda.manual_seed(seed)\\ntorch.cuda.manual_seed_all(seed)\\n\\n# Ensure deterministic behavior\\ntorch.backends.cudnn.deterministic = True\\ntorch.backends.cudnn.benchmark = False\\n\\n# Set CUBLAS workspace config to ensure deterministic cuBLAS\\nimport os\\nos.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\\n\\ntorch.use_deterministic_algorithms(True)\\ntorch.set_num_threads(1)\\n\\n# Load the model\\nmodel = torch.jit.load('test.pt')\\nmodel = model.to(torch.device('cuda:0'))\\nmodel = model.half()\\n\\n# Create a random array\\ntorch.manual_seed(0)\\nrandom_arr = torch.randn(1,1,224, 224, 224, dtype = torch.half).to(torch.device('cuda:0'))\\npred = model(random_arr).to(torch.device('cpu')).detach().numpy()\\n\\nThe pred variable is different in each run, max. difference is about 3e-2. Any help would be appreciated. Thanks!   \n",
       "3      import torch.nn as nn\\nimport torch\\n\\nclass Foo(nn.Module):\\n    def __init__(self, input_size=20, output_size=100):\\n        super().__init__()\\n        self.input_size = input_size\\n        self.output_size = output_size\\n\\n        self.fc0 = nn.Linear(self.input_size, 30)\\n        self.fc1 = nn.Linear(30, 40)\\n        self.fc_out = nn.Linear(40, self.output_size)\\n\\n    def increment_output_size(self, copy_idx: int):\\n        old_output_size = self.output_size\\n        old_fc_out = self.fc_out\\n\\n        self.output_size += 1\\n        self.fc_out = nn.Linear(40, self.output_size)\\n        with torch.no_grad():\\n            self.fc_out.weight.data[:old_output_size] = old_fc_out.weight.data\\n            self.fc_out.weight.data[-1] = old_fc_out.weight.data[copy_idx].clone()\\n            self.fc_out.bias.data[:old_output_size] = old_fc_out.bias.data\\n            self.fc_out.bias.data[-1] = old_fc_out.bias.data[copy_idx].clone()\\n\\n\\nif __name__ == \"__main__\":\\n    # SETUP MODEL AND OPTIMIZER\\n    model = Foo()\\n    optimizer = torch.optim.Adam(model.parameters())\\n\\n    # DO SOME TRAINING HERE (Adam optimizer will hold state stat for each parameter)\\n    # ...\\n\\n    # MODIFY MODEL\\n    model.increment_output_size(copy_idx=25)\\n\\n    # UPDATE OPTIMIZER\\n    #  1. For parameters (weights/bias) of model.fc0 and model.fc1, the state should be retained.\\n    #  2. For parameter fc_out, which is modified:\\n    #     a. for model.fc_out.weight/bias[:100], preserve the corresponding states in Adam\\n    #     b. for model.fc_out.weight/bias[101], clone the state corresponding to model.fc_out.weight[25]\\n\\n    # DO SOME MORE TRAINING HERE\\n    # ...\\n\\n    print(\"Done\")\\n\\nThe code above attempts to train a model that, throughout the training process, may dynamically modify its self.fc_out module to accommodate for increase in the number of classes. I want it so that the existing Adam optimizer can adaptively update its internal state in accordance to the model modification. This means both updating the relevant items in self.updater.optimizer.param_groups[0][\"params\"] and self.updater.optimizer.state (and other stuff, if necessary).\\nHow can I do this? Specifically:\\n\\nHow can I index the optimizer fields/keys relevant to the self.fc_out?\\nHow do I replace the relevant optimizer params and states? Is it sufficient to do self.updater.optimizer.param_groups[0][\"params\"][index_of_fc_out_weight] = model.fc_out.weight and self.updater.optimizer.state[index_of_fc_out_weight] = new_fc_out_state?\\nAre there any other fields or under-the-hood mechanisms that I need to be aware of?\\n\\nAny help is appreciated.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Hello,\\nI am profiling my training code and I’m struggling to understand the output. The different steps seem to be taking different amount of time and I am not sure why.\\nimage3082×1044 378 KB\\nA simplified version of my code would be:\\nwith profiler.profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], ...) as p:\\n    for x, y in training_dataloader:\\n        p.step()\\n        out = model(x)\\n        loss = loss_fn(out,y)\\n        loss.backward()\\n        optim.step()\\n        optim.zero_grad()\\n\\nScheduler is set to skip_first=10, wait=5, warmup=1, active=5, repeat=1\\nIf I then add some operation that downloads something to cpu memory such as l = loss.item() after the optimizer step, I get something like this:\\nimage3048×1050 292 KB\\nIn both scenarios the average train step is the same even though each profiler step seems to vary in time in the first case.\\nI am a bit confused by this behaviour. My hypothesis is that my profiler might be measuring the async python function calls and not the actual cuda kernels. But isn’t the point of the profiler to measure the cuda kernel time? I am interested in analysing how long does my CPU and GPU take in each part of the code, and I guess here I am just seeing the CPU?\\nIf I go down below in the GPU thread part of the profiler, I get this, which I don’t understand or is giving me too little information about how long is spent in each kernel by the gpu.\\nimage4106×798 183 KB\\nNote that this screenshot is taken for the first example where i do NOT add l = loss.item() and all the different steps are taking different time in cpu time. Yet in the GPU thread they seem to be taking the same amount of time.\\nI would appreciate any insights on why this is happening or if my intuitions are correct and what is the best way to measure how long is my GPU spending in each kernel.\\nI am using a 4090 GPU and the model is a simple UNet with 128x128 image input.\\nThanks,\\nBenet   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ...   \n",
       "30629                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     So i just used packer to bake my own images for GCE and ran into the following situation.\\nInstalled CUDA 9.0 and everything worked fine, I could train my models on the GPU.\\nAfte a while I noticed I forgot to install cuDNN, however it seems that pytorch does not complain about this. On an image with only CUDA installed, if I run\\ntorch.backends.cudnn.version() I get 7102 and torch.backends.cudnn.enabled == True\\nWhen I did install cuDNN from https://developer.nvidia.com/cudnn, everything still worked fine, I still got the same outputs for the two command above, but I didn’t get significant speedups.\\nDoes this mean if one installs only CUDA and PyTorch, cuDNN also gets magically installed? Or is there a way how to check if pytorch is really using the speedups promised from cuDNN?\\nAny advice? Thanks   \n",
       "30630                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Hi everyone!\\nI saw several topics on how to feed a 3D tensor into a Neural Network but it’s not quite clear to me what’s happening.\\nI’m working with stock data and for each individual stock I have a 2 dimension torch containing several information (in columns) for each day. So, for each stock I have a matrix with features for column and days for rows and my NN works fine for a single stock. However, I’d like to apply the same operations for several stocks, thus yielding a 3d torch with the third dimension referring to each individual asset.\\nIf I reshape the data into a 2d torch (stacking the features) I think i’ll lose information when trying to predict a single outcome with the trained NN. I’ve also found some topics explaining how to pass a 3d tensor to a Linear pass, but I understand they will make the Linear regression layer by layer, whereas I’d like to minimize the error for the whole 3d tensor.\\nDo you have any thoughts on that that might help me out?\\nthanks!   \n",
       "30631                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Hi,\\nI’m just getting some NaN in some module parameters (word embedding weights).\\nI just indentified that the NaN comes with the optim.step() instruction.\\nWhat could typically leads to this? (sharing code would be unpractical as there is quite a lot of things, hard to get an atomic reproducible example :/)\\nInterestingly enough, this problem only appears on some data (I’ve some toy data to test based on the PTB dataset with target = source; target = reversed source or a dataset with input=random integer sequence, target=sorted sequence)\\nThx\\n\\nmy model is made of 2-brnn lstm encoder with shared embedding, 2-lstm decoder with temporal attention over source and intra-decoder attention (as described in Paulus et al, (2017)).   \n",
       "30632                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Since for nn.Upsample, it’s possible to deal with 2D Tensor, so what’s the difference here between the upsample and the convtranspose2d. Thank you   \n",
       "30633                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               when i use nn.CrossEntropyLoss to train a segmentation model.But it shows that 'lonly batches of spatial targets supported(non-empty 3D tensors)but got targets of size :[2,1,512,512]\\nthe output_size of the model is [2,2,512,512](batch_size = 2 and num_classes = 2]\\nThanks   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     all_answers  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [Can you share some debugging info like printing type(img) and img.dtype I wrote the same line of code and it worked for me.\\nThere has to be some bug in the data loading process of the image., Hello It seems you are getting the error because the argument to from_numpy function is a single value rather than array.\\nIn numpy, there is difference between np.array(1) and np.array([1]) and both are completely different data types.\\nTry torch.from_numpy(np.asarray(x))., Hello, I have encountered the same problem. Do you have any solutions?Thank you, Try\\ntorch.as_tensor(np.array(pil_img).astype('float'))\\nIt worked for me., Have you fix this problem? I encounter this problem too…, Could you post a minimal code snippet to reproduce this error?, I found it is because of the version of numpy…\\n\\n\\n\\n信工 刘蓬博\\n邮箱：pengbo18555@163.com\\n签名由 网易邮箱大师 定制, It’s also happening to me on numpy 1.17.4, my own solution is to downgrade to 1.16.4, thanks! it worked for me.\\nNumpy version -  1.19.5, It worked for me. Thank you @raghavendragaleppa, I was working with tabular MNIST data !!\\none possible solution that worked for me was,\\nx_train.reset_index(drop=True,inplace=True)\\nx_test.reset_index(drop=True,inplace=True)\\ny_train.reset_index(drop=True,inplace=True)\\ny_test.reset_index(drop=True,inplace=True)\\nhope it helps for those using TABULAR dataset, iam trying to run a simple dqn code for cartpole environment in my computer.                                                        This is my code updated as you said;\\n    env = gym.make('CartPole-v1')\\n    q = Qnet()\\n    q_target = Qnet()\\n    q_target.load_state_dict(q.state_dict())\\n    memory = ReplayBuffer()\\n\\n    print_interval = 20\\n    score = 0.0  \\n    optimizer = optim.Adam(q.parameters(), lr=learning_rate)\\n\\n    for n_epi in range(10000):\\n        epsilon = max(0.01, 0.08 - 0.01*(n_epi/200)) #Linear annealing from 8% to 1%\\n        s = env.reset()\\n        done = False\\n        while not done:\\n            **a = q.sample_action(torch.from_numpy(np.asarray(s)).float(), epsilon)**      \\n            s_prime, r, done, info = env.step(a)\\n            done_mask = 0.0 if done else 1.0\\n            memory.put((s,a,r/100.0,s_prime, done_mask))\\n            s = s_prime\\n\\nbut iam getting the following error again where everything is fine\\nTraceback (most recent call last):\\nFile “d:\\college\\final yr\\project\\rl-series\\dqn\\simpledqn.py”, line 114, in \\nmain()\\nFile “d:\\college\\final yr\\project\\rl-series\\dqn\\simpledqn.py”, line 93, in main\\na = q.sample_action(torch.from_numpy(np.asarray(s)), epsilon)\\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part., Thanks! This solved my issue., I think this problem may arise from torch.from_numpy(array)'s mismatching with numpy version or dtype,and use other way of generating a tensor from numpy is a solution.]  \n",
       "1      [Are you seeing the same message, if you remove the multiprocessing code (I assume this is triggering it)?, Sorry for my late response and thank you for the reply!\\nI pinned the trigger of this warning. It happens if I set num_workers > 0 in torch.utils.data.DataLoader, instead of being caused by nn.DataParallel().\\nAny idea how to fix it? Is it probably due to that I set torch.multiprocessing.set_start_method('spawn', force=True)?, I have issued the same problem when setting num of workers to more then 0. @ptrblck, any solution ?, Unfortunately, I don’t have suggestions, as I don’t fully understand the use case of using torch.multiprocessing as well as multiple workers (which itself will use multiple processes), so could you explain the use case a bit more?, Hi @ptrblck, I came across the same issue and was intrigued by your remark:\\n\\n\\n\\n ptrblck:\\n\\nI don’t fully understand the use case of using torch.multiprocessing as well as multiple workers\\n\\n\\nFor one, isn’t it good to be able to process/load the data using a separate process, apart from the training process(es), in order to not tax them with extra processing load? Further, although it’s not my use case, loading the data might involve some heavy preprocessing, warranting even more than one data loader workers per training process; e.g. in the case in of some vision applications.\\nMaybe you have a completely different idea about this and give us your insight in to this topic.\\nThanks in advance., I totally agree with you and also think that multiple processes by themselves are useful, should be used for the data loading and process, and would yield a speedup in the overall training pipeline.\\nThis can be easily achieved with the num_workers argument of the DataLoader.\\nMy comment might not have been clear enough, but I was wondering about the use case to use the multiprocessing package manually in the training script as well as multiple workers (which will again spawn multiple processes, so you would end up with a “nested” multiprocessing workload), as I would imagine that using the simpler approach of setting num_workers>=1 should already do the job., Ah, ok, sorry, I didn’t notice the part about using the multiprocessing package separately. I think this is because I had the same issue just using DDP and Dataloaders with num_workers > 0. I get these errors just before my script exits; I already am a good citizen by using dist.barrier() to wait for all training processes to complete before exiting.\\nWhen I set the num_workers to zero the script exits smoothly without any errors. In the past I have often used multiple DataLoader workers in a DDP context and never had this issue. I’m wondering if this is something that sneaked in to a recent Pytorch release or is related to recent a CUDA version?\\nMy setup:\\n| NVIDIA-SMI 470.86 Driver Version: 470.86 CUDA Version: 11.4     |\\n\\n$ pip show torch\\nName: torch\\nVersion: 1.10.0\\n\\nThis is on a 4x V100 machine with Ubuntu.\\nIt might also be in my script of course., Ok, I dove a bit more in to this, and found the issue. In this particular instance I am using a model library where the author unfortunately had added the batch collate function as a method to the model class. Because of this the model self is also transported to the DataLoader workers.\\nWhen the training scripts exits the DataLoader worker processes are killed too, without properly dealing with the Tensors that are copied to the worker.\\nI refactored all the batch collating code out of the model class and thus made it independent of the self of the model instance. This resolved the issue, exiting the script is very smooth now!\\nSo, if anyone gets this error, it could be because your are copying the model over to the DataLoader workers without knowing it., Hi @visionscaper, I’m encountering the same issue. I’m currently using pytorch lightning to write my model. When I set the num_worker > 0 in the dataloader, the warning will occur. I’m a beginner in pytorch. Could you give me some example that how did you refactor your batch collating code out of model class? I don’t know how to do it., Hi @sjtuhl, if you have a similar issue to mine, somehow your model is linked to your dataset, collate_fn or other object given to a DataLoader. Because of this, when you set num_worker > 0, the model is copied to the DataLoader workers. For instance, if your dataset is a property of your model class instance (which is just bad design), not only your dataset is copied to the workers, but everything it is “attached” to as well.\\nI hope this makes sense to you. I can’t really help you without inspecting your code., Hi @visionscaper, I have the same issue as you. My data collate fn is written inside the dataset model. There are some tensors my collate_fn need, stored in the dataset model. I wonder if there is a way to avoid moving the collate_fn out and escape the error?, This warning is caused by tensors (or other objects) that are not being properly cleaned up (released) on the CUDA device before the process they belonged to was terminated.\\nAs it was for me in my case, and seems to be the case for mostly everyone else, the culprit behind this warning has to do with moving objects to, or owning objects on, the CUDA device from inside of one of the DataLoader worker processes, and the worker process being terminated before the  objects are released from CUDA.\\nMoving tensors to CUDA inside a collate_fn that is passed to a DataLoader where num_workers > 0 - which just means that a child process will be created for each worker - is an example of this, and is exactly what I was doing. In my training loop then, after all the training samples were iterated through, my DataLoader worker processes would be terminated and I would get this warning.\\nAs tempting as it is to move batches to CUDA inside the collate_fn, and though it may even provide some performance gains, the potential for a memory leak or some other resource management issue along with the annoying warning made me rethink my strategy. I ended up just relocating this logic to the first line in my training loop (on CPU - main process) where I move each batch to CUDA before my forward pass which I think is generally recommended anyway - never looked back since.\\nAlternatively, if you really wanted to, you could keep whatever objects you want on the CUDA device inside your DataLoader worker processes if you set persistent_workers=True in your DataLoader constructor and not encounter this warning until your DataLoader is entirely deallocated. You may encounter other issues though like running out of memory on the GPU, but I think for some use cases, maybe doing this could be beneficial.\\nHope this helps.]  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [Could you post a minimal and executable code snippet reproducing the issue?, Thanks for your response. Here are two scripts, please save them as script_1.py and script_2.py in the working directory. For this experiment, I’m using a model from huggingface, but the results are similar with my own segmentation model (nnU-Net).\\n# Save this as script_1.py\\n\\nimport torch\\nimport numpy as np\\nimport random\\nimport requests\\nimport pickle\\nimport argparse\\n\\nif __name__ == '__main__':\\n\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument(\"--result_filename\", help=\"location to save the result prediction\")\\n\\n    args = parser.parse_args()\\n    \\n    # Set the seed for all random number generators\\n    seed = 42\\n    torch.manual_seed(seed)\\n    random.seed(seed)\\n    np.random.seed(seed)\\n    torch.cuda.manual_seed(seed)\\n    torch.cuda.manual_seed_all(seed)\\n\\n    # Ensure deterministic behavior\\n    torch.backends.cudnn.deterministic = True\\n    torch.backends.cudnn.benchmark = False\\n\\n    # Set CUBLAS workspace config to ensure deterministic cuBLAS\\n    import os\\n    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\\n\\n    torch.use_deterministic_algorithms(True)\\n    torch.set_num_threads(1)\\n\\n    # Download the file\\n    url = 'https://huggingface.co/spaces/Xajimel/Practica3/resolve/main/unet.pth'\\n    response = requests.get(url)\\n    with open('model.pt', 'wb') as f:\\n        f.write(response.content)\\n\\n    model = torch.jit.load('model.pt')\\n    model = model.to(torch.device('cuda:0'))\\n    model = model.half()\\n\\n    # Create a random array\\n    torch.manual_seed(0)\\n    random_arr = torch.randn(1, 3, 224, 224, dtype = torch.half).to(torch.device('cuda:0'))\\n    pred = model(random_arr).to(torch.device('cpu')).detach().numpy()\\n\\n    with open(args.result_filename, 'wb') as f:\\n        pickle.dump(pred, f)\\n\\n# Save this as script_2.py\\n\\nimport pickle\\nimport numpy as np\\n\\nwith open('pred1.pkl', 'rb') as f:\\n    a = pickle.load(f)\\n\\nwith open('pred2.pkl', 'rb') as f:\\n    b = pickle.load(f)\\n\\nprint('Length of a: ', len(a))\\nprint('Length of b: ', len(b))\\n\\nprint('Shape of first element in a: ', a[0].shape)\\nprint('Shape of first element in b: ', b[0].shape)\\n\\ndiff = a[0] - b[0]\\n\\nprint('Min diff: ', np.min(diff))\\nprint('Max diff: ', np.max(diff))\\n\\nRun this with the following commands.\\npython script_1.py --result_filename pred1.pkl\\npython script_1.py --result_filename pred2.pkl\\npython script_2.py\\n\\nSomething I found interesting was that if I change the url in script_1.py to a different model (say this one), I see no differences in the prediction.\\nI wonder if the issue then is non-determinism in some layers in the nnU-Net model or the way I’m saving the model. This is how I save the model.\\nself.network = self.network.to(self.device)\\nself.network.eval()\\ntorch.use_deterministic_algorithms(True)\\ntraced_model = torch.jit.trace(self.network, torch.randn(1, 1, 224, 224, 224).to(self.device))\\ntorch.jit.save(traced_model, 'model.pt')\\n\\nLet me know what you think or if you need some more info. Thanks!, I cannot reproduce the issue and see:\\nLength of a:  1\\nLength of b:  1\\nShape of first element in a:  (5, 224, 224)\\nShape of first element in b:  (5, 224, 224)\\nMin diff:  0.0\\nMax diff:  0.0, This is what I see. I’m on torch 2.3.0+cu121 if that helps.\\nLength of a:  1\\nLength of b:  1\\nShape of first element in a:  (5, 224, 224)\\nShape of first element in b:  (5, 224, 224)\\nMin diff:  -0.01563\\nMax diff:  0.01172, @ptrblck On the machine that I was initially testing on, I see the issue on torch 2.3.0+cu121 and torch 2.4.0+cu121. On another machine, I don’t see the issue in either versions. These machines have different GPUs (earlier: A40, now: RTX 3050 Ti).\\nCould the underlying GPU make a difference?]  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             []  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [benoriol:\\n\\nIf I then add some operation that downloads something to cpu memory such as l = loss.item() after the optimizer step, I get something like this:\\n\\n\\nThis is expected since the item() call is synchronizing the GPU.\\n\\n\\n\\n benoriol:\\n\\nI am a bit confused by this behaviour. My hypothesis is that my profiler might be measuring the async python function calls and not the actual cuda kernels.\\n\\n\\nYes, this seems to be the case and I would expect to see different time lines: one for the host and another one for the device.\\nI’m not familiar with the native PyTorch profiler visualization as I am using Nsight Systems for profiling. You could check this post for instructions on how to use nsys., That makes sense, thanks.\\nOne more question, is there a limit to the number of async python calls that pytorch can do without waiting for the actual computation to be done in the GPU? It seems that it is doing multiple faster non-blocking calls to training steps (#16 and #17) before it starts to take longer in step #18, I assume waiting for GPU to finish the previous ones. In general, what is a good resource where I can learn more about how Pytorch works under the hood?\\nIn any case I will switch to nsys profiler, seems like a much better option. Thanks a lot., benoriol:\\n\\nOne more question, is there a limit to the number of async python calls that pytorch can do without waiting for the actual computation to be done in the GPU?\\n\\n\\nYes, the queue handling the CUDA kernel launches is limited and the host will be blocked if the queue is saturated.]  \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ...  \n",
       "30629                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [How did you install PyTorch?\\nThe binaries are shipped with CUDA and cuDNN already., I used a script like this, to install CUDA, cuDNN and Python and then used pipenv install torch to install PyTorch. The image was based on Google Clouds “ubuntu-1604-lts”. But even if I comment out the line that installs cuDNN nothing seems to change for my PyTorch installation?\\n# install CUDA\\necho \"Checking for CUDA and installing.\"\\n# Check for CUDA and try to install.\\nif ! dpkg-query -W cuda-9-0; then\\n  # The 16.04 installer works with 16.10.\\n  wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_9.0.176-1_amd64.deb\\n  sudo apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/7fa2af80.pub\\n  sudo dpkg -i cuda-repo-ubuntu1604_9.0.176-1_amd64.deb\\n  sudo apt-get update\\n  sudo apt-get install cuda-9-0 -y\\nfi\\n\\n# install cuDNN\\nsudo dpkg -i /tmp/libcudnn7_7.1.4.18-1+cuda9.0_amd64.deb\\n\\n\\n# install python\\nsudo add-apt-repository ppa:deadsnakes/ppa\\nsudo apt-get update\\nsudo apt-get install -y python3.6\\nsudo apt-get install -y python3-pip\\n\\n# install pipenv\\nsudo pip3 install pipenv, Ok, I just found an answer by soumith on another thread:\\n“if you want to use pytorch with an NVIDIA GPU, all you need to do is install pytorch binaries and start using it. We ship with everything in-built (pytorch binaries include CUDA, CuDNN, NCCL, MKL, etc.).”\\nso that means the whole installing CUDA and cuDNN on Ubuntu shenanigans are actually not necessary at all?! That would also explain my confusion, why I get the same time to train no matter if I install cudnn or not\\nsorry for the confusion, Yes, you just need to install the NVIDIA drivers and the binaries will come with the other libs.\\nIf you want to build from source, you would need to install CUDA, cuDNN etc., Could you check your LD_LIBRARY_PATH to see if you have some libs linking against your own libcudart as described in this issue?]  \n",
       "30630                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [Would you like to use the same linear layers for both inputs?\\nIf so, you could just create a tensor of the shape [batch_dim, nb_stocks, in_features] and the layers will be applied on each nb_stock dimension., I tried that, but it seems the output converges on the out layer. It is, instead of the output adjusting to the stock series, it returns a horizontal line. I’m not sure what the problem might be, Could you try to fit a very small data sample (e.g. just one or five samples) and see if your model correctly overfits on this small sample?\\nIf that’s not possible, there might be other problems in your code.\\nHowever, if that works, I would try to scale up the problem using a bit more samples and see, when the model training breaks. Maybe your model’s architecture is currently not suitable for the problem or your model has just not enough capacity.]  \n",
       "30631                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [The problem was very task specific.\\nFor some reason I was not using part of a parameter (but only a slice of the matrix), which, I suppose, made it a NaN, I have the same issue as you.]  \n",
       "30632                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [While nn.Upsample uses some interpolation technique, nn.ConvTranspose uses trainable filters to create your output (similar to vanilla conv layers)., Thank you for your information, can you explain the pros and cons of these two function.\\nIs the upsample recover more context information or the ConvTranspose?, Generally speaking, the ConvTranpose layer might learn some features as it’s using trainable parameters, while Upsample just interpolates.\\nThe former approach would thus have more parameters (more capacity) and might therefore overfit easier.\\nI can’t really tell which approach works better in which situation, as I’ve seen both methods used for certain use cases.\\nWhile it seems that ConvTranpose layers are preferred in GANs, I’ve seen some models using Upsample performed better for segmentation tasks. This is just my biased observation, so this is not a recommendation to choose one over the other.\\nYou should try both approaches and see, how your model performs., Thank you, that helps a lot.]  \n",
       "30633                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [Have you tried squeezeing the targets to [2, 512, 512]?, Thank you very much.  When i squeeze ing the targets to  [2, 512, 512] ,it is work.]  \n",
       "\n",
       "[30634 rows x 4 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a column that caluclates the total comments number accross all threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()  # Create a deep copy of the DataFrame\n",
    "df['list_length'] = df['all_answers'].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We got 76572 total answers\n"
     ]
    }
   ],
   "source": [
    "print(f'We got {df[\"list_length\"].sum()} total answers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicates if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>question</th>\n",
       "      <th>all_answers</th>\n",
       "      <th>list_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]</td>\n",
       "      <td>I got this warning at the end of each epoch when using multiple GPUs:\\n[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\\nBut it doesn’t seem to affect the training since the result is as good as it is.\\nBut I would still like to know what the probable cause is and how to solve it  \\nI simply use: model = torch.nn.DataParallel(model) to enable multi-GPUs.\\nBesides, I also added torch.multiprocessing.set_start_method('spawn', force=True) in my code. Don’t know whether it has any effect on this.\\nThank you for the answer in advance.</td>\n",
       "      <td>[Are you seeing the same message, if you remove the multiprocessing code (I assume this is triggering it)?, Sorry for my late response and thank you for the reply!\\nI pinned the trigger of this warning. It happens if I set num_workers &gt; 0 in torch.utils.data.DataLoader, instead of being caused by nn.DataParallel().\\nAny idea how to fix it? Is it probably due to that I set torch.multiprocessing.set_start_method('spawn', force=True)?, I have issued the same problem when setting num of workers to more then 0. @ptrblck, any solution ?, Unfortunately, I don’t have suggestions, as I don’t fully understand the use case of using torch.multiprocessing as well as multiple workers (which itself will use multiple processes), so could you explain the use case a bit more?, Hi @ptrblck, I came across the same issue and was intrigued by your remark:\\n\\n\\n\\n ptrblck:\\n\\nI don’t fully understand the use case of using torch.multiprocessing as well as multiple workers\\n\\n\\nFor one, isn’t it good to be able to process/load the data using a separate process, apart from the training process(es), in order to not tax them with extra processing load? Further, although it’s not my use case, loading the data might involve some heavy preprocessing, warranting even more than one data loader workers per training process; e.g. in the case in of some vision applications.\\nMaybe you have a completely different idea about this and give us your insight in to this topic.\\nThanks in advance., I totally agree with you and also think that multiple processes by themselves are useful, should be used for the data loading and process, and would yield a speedup in the overall training pipeline.\\nThis can be easily achieved with the num_workers argument of the DataLoader.\\nMy comment might not have been clear enough, but I was wondering about the use case to use the multiprocessing package manually in the training script as well as multiple workers (which will again spawn multiple processes, so you would end up with a “nested” multiprocessing workload), as I would imagine that using the simpler approach of setting num_workers&gt;=1 should already do the job., Ah, ok, sorry, I didn’t notice the part about using the multiprocessing package separately. I think this is because I had the same issue just using DDP and Dataloaders with num_workers &gt; 0. I get these errors just before my script exits; I already am a good citizen by using dist.barrier() to wait for all training processes to complete before exiting.\\nWhen I set the num_workers to zero the script exits smoothly without any errors. In the past I have often used multiple DataLoader workers in a DDP context and never had this issue. I’m wondering if this is something that sneaked in to a recent Pytorch release or is related to recent a CUDA version?\\nMy setup:\\n| NVIDIA-SMI 470.86 Driver Version: 470.86 CUDA Version: 11.4     |\\n\\n$ pip show torch\\nName: torch\\nVersion: 1.10.0\\n\\nThis is on a 4x V100 machine with Ubuntu.\\nIt might also be in my script of course., Ok, I dove a bit more in to this, and found the issue. In this particular instance I am using a model library where the author unfortunately had added the batch collate function as a method to the model class. Because of this the model self is also transported to the DataLoader workers.\\nWhen the training scripts exits the DataLoader worker processes are killed too, without properly dealing with the Tensors that are copied to the worker.\\nI refactored all the batch collating code out of the model class and thus made it independent of the self of the model instance. This resolved the issue, exiting the script is very smooth now!\\nSo, if anyone gets this error, it could be because your are copying the model over to the DataLoader workers without knowing it., Hi @visionscaper, I’m encountering the same issue. I’m currently using pytorch lightning to write my model. When I set the num_worker &gt; 0 in the dataloader, the warning will occur. I’m a beginner in pytorch. Could you give me some example that how did you refactor your batch collating code out of model class? I don’t know how to do it., Hi @sjtuhl, if you have a similar issue to mine, somehow your model is linked to your dataset, collate_fn or other object given to a DataLoader. Because of this, when you set num_worker &gt; 0, the model is copied to the DataLoader workers. For instance, if your dataset is a property of your model class instance (which is just bad design), not only your dataset is copied to the workers, but everything it is “attached” to as well.\\nI hope this makes sense to you. I can’t really help you without inspecting your code., Hi @visionscaper, I have the same issue as you. My data collate fn is written inside the dataset model. There are some tensors my collate_fn need, stored in the dataset model. I wonder if there is a way to avoid moving the collate_fn out and escape the error?, This warning is caused by tensors (or other objects) that are not being properly cleaned up (released) on the CUDA device before the process they belonged to was terminated.\\nAs it was for me in my case, and seems to be the case for mostly everyone else, the culprit behind this warning has to do with moving objects to, or owning objects on, the CUDA device from inside of one of the DataLoader worker processes, and the worker process being terminated before the  objects are released from CUDA.\\nMoving tensors to CUDA inside a collate_fn that is passed to a DataLoader where num_workers &gt; 0 - which just means that a child process will be created for each worker - is an example of this, and is exactly what I was doing. In my training loop then, after all the training samples were iterated through, my DataLoader worker processes would be terminated and I would get this warning.\\nAs tempting as it is to move batches to CUDA inside the collate_fn, and though it may even provide some performance gains, the potential for a memory leak or some other resource management issue along with the annoying warning made me rethink my strategy. I ended up just relocating this logic to the first line in my training loop (on CPU - main process) where I move each batch to CUDA before my forward pass which I think is generally recommended anyway - never looked back since.\\nAlternatively, if you really wanted to, you could keep whatever objects you want on the CUDA device inside your DataLoader worker processes if you set persistent_workers=True in your DataLoader constructor and not encounter this warning until your DataLoader is entirely deallocated. You may encounter other issues though like running out of memory on the GPU, but I think for some use cases, maybe doing this could be beneficial.\\nHope this helps.]</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>Determinism in inference</td>\n",
       "      <td>I have the following code snippet. When I run the script consecutively, I get different results in prediction. Is there a setting I’m missing?\\nimport torch\\nimport numpy as np\\nimport random\\n\\n# Set the seed for all random number generators\\nseed = 42\\ntorch.manual_seed(seed)\\nrandom.seed(seed)\\nnp.random.seed(seed)\\ntorch.cuda.manual_seed(seed)\\ntorch.cuda.manual_seed_all(seed)\\n\\n# Ensure deterministic behavior\\ntorch.backends.cudnn.deterministic = True\\ntorch.backends.cudnn.benchmark = False\\n\\n# Set CUBLAS workspace config to ensure deterministic cuBLAS\\nimport os\\nos.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\\n\\ntorch.use_deterministic_algorithms(True)\\ntorch.set_num_threads(1)\\n\\n# Load the model\\nmodel = torch.jit.load('test.pt')\\nmodel = model.to(torch.device('cuda:0'))\\nmodel = model.half()\\n\\n# Create a random array\\ntorch.manual_seed(0)\\nrandom_arr = torch.randn(1,1,224, 224, 224, dtype = torch.half).to(torch.device('cuda:0'))\\npred = model(random_arr).to(torch.device('cpu')).detach().numpy()\\n\\nThe pred variable is different in each run, max. difference is about 3e-2. Any help would be appreciated. Thanks!</td>\n",
       "      <td>[Could you post a minimal and executable code snippet reproducing the issue?, Thanks for your response. Here are two scripts, please save them as script_1.py and script_2.py in the working directory. For this experiment, I’m using a model from huggingface, but the results are similar with my own segmentation model (nnU-Net).\\n# Save this as script_1.py\\n\\nimport torch\\nimport numpy as np\\nimport random\\nimport requests\\nimport pickle\\nimport argparse\\n\\nif __name__ == '__main__':\\n\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument(\"--result_filename\", help=\"location to save the result prediction\")\\n\\n    args = parser.parse_args()\\n    \\n    # Set the seed for all random number generators\\n    seed = 42\\n    torch.manual_seed(seed)\\n    random.seed(seed)\\n    np.random.seed(seed)\\n    torch.cuda.manual_seed(seed)\\n    torch.cuda.manual_seed_all(seed)\\n\\n    # Ensure deterministic behavior\\n    torch.backends.cudnn.deterministic = True\\n    torch.backends.cudnn.benchmark = False\\n\\n    # Set CUBLAS workspace config to ensure deterministic cuBLAS\\n    import os\\n    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\\n\\n    torch.use_deterministic_algorithms(True)\\n    torch.set_num_threads(1)\\n\\n    # Download the file\\n    url = 'https://huggingface.co/spaces/Xajimel/Practica3/resolve/main/unet.pth'\\n    response = requests.get(url)\\n    with open('model.pt', 'wb') as f:\\n        f.write(response.content)\\n\\n    model = torch.jit.load('model.pt')\\n    model = model.to(torch.device('cuda:0'))\\n    model = model.half()\\n\\n    # Create a random array\\n    torch.manual_seed(0)\\n    random_arr = torch.randn(1, 3, 224, 224, dtype = torch.half).to(torch.device('cuda:0'))\\n    pred = model(random_arr).to(torch.device('cpu')).detach().numpy()\\n\\n    with open(args.result_filename, 'wb') as f:\\n        pickle.dump(pred, f)\\n\\n# Save this as script_2.py\\n\\nimport pickle\\nimport numpy as np\\n\\nwith open('pred1.pkl', 'rb') as f:\\n    a = pickle.load(f)\\n\\nwith open('pred2.pkl', 'rb') as f:\\n    b = pickle.load(f)\\n\\nprint('Length of a: ', len(a))\\nprint('Length of b: ', len(b))\\n\\nprint('Shape of first element in a: ', a[0].shape)\\nprint('Shape of first element in b: ', b[0].shape)\\n\\ndiff = a[0] - b[0]\\n\\nprint('Min diff: ', np.min(diff))\\nprint('Max diff: ', np.max(diff))\\n\\nRun this with the following commands.\\npython script_1.py --result_filename pred1.pkl\\npython script_1.py --result_filename pred2.pkl\\npython script_2.py\\n\\nSomething I found interesting was that if I change the url in script_1.py to a different model (say this one), I see no differences in the prediction.\\nI wonder if the issue then is non-determinism in some layers in the nnU-Net model or the way I’m saving the model. This is how I save the model.\\nself.network = self.network.to(self.device)\\nself.network.eval()\\ntorch.use_deterministic_algorithms(True)\\ntraced_model = torch.jit.trace(self.network, torch.randn(1, 1, 224, 224, 224).to(self.device))\\ntorch.jit.save(traced_model, 'model.pt')\\n\\nLet me know what you think or if you need some more info. Thanks!, I cannot reproduce the issue and see:\\nLength of a:  1\\nLength of b:  1\\nShape of first element in a:  (5, 224, 224)\\nShape of first element in b:  (5, 224, 224)\\nMin diff:  0.0\\nMax diff:  0.0, This is what I see. I’m on torch 2.3.0+cu121 if that helps.\\nLength of a:  1\\nLength of b:  1\\nShape of first element in a:  (5, 224, 224)\\nShape of first element in b:  (5, 224, 224)\\nMin diff:  -0.01563\\nMax diff:  0.01172, @ptrblck On the machine that I was initially testing on, I see the issue on torch 2.3.0+cu121 and torch 2.4.0+cu121. On another machine, I don’t see the issue in either versions. These machines have different GPUs (earlier: A40, now: RTX 3050 Ti).\\nCould the underlying GPU make a difference?]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>Weird Pytorch profiler output</td>\n",
       "      <td>Hello,\\nI am profiling my training code and I’m struggling to understand the output. The different steps seem to be taking different amount of time and I am not sure why.\\nimage3082×1044 378 KB\\nA simplified version of my code would be:\\nwith profiler.profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], ...) as p:\\n    for x, y in training_dataloader:\\n        p.step()\\n        out = model(x)\\n        loss = loss_fn(out,y)\\n        loss.backward()\\n        optim.step()\\n        optim.zero_grad()\\n\\nScheduler is set to skip_first=10, wait=5, warmup=1, active=5, repeat=1\\nIf I then add some operation that downloads something to cpu memory such as l = loss.item() after the optimizer step, I get something like this:\\nimage3048×1050 292 KB\\nIn both scenarios the average train step is the same even though each profiler step seems to vary in time in the first case.\\nI am a bit confused by this behaviour. My hypothesis is that my profiler might be measuring the async python function calls and not the actual cuda kernels. But isn’t the point of the profiler to measure the cuda kernel time? I am interested in analysing how long does my CPU and GPU take in each part of the code, and I guess here I am just seeing the CPU?\\nIf I go down below in the GPU thread part of the profiler, I get this, which I don’t understand or is giving me too little information about how long is spent in each kernel by the gpu.\\nimage4106×798 183 KB\\nNote that this screenshot is taken for the first example where i do NOT add l = loss.item() and all the different steps are taking different time in cpu time. Yet in the GPU thread they seem to be taking the same amount of time.\\nI would appreciate any insights on why this is happening or if my intuitions are correct and what is the best way to measure how long is my GPU spending in each kernel.\\nI am using a 4090 GPU and the model is a simple UNet with 128x128 image input.\\nThanks,\\nBenet</td>\n",
       "      <td>[benoriol:\\n\\nIf I then add some operation that downloads something to cpu memory such as l = loss.item() after the optimizer step, I get something like this:\\n\\n\\nThis is expected since the item() call is synchronizing the GPU.\\n\\n\\n\\n benoriol:\\n\\nI am a bit confused by this behaviour. My hypothesis is that my profiler might be measuring the async python function calls and not the actual cuda kernels.\\n\\n\\nYes, this seems to be the case and I would expect to see different time lines: one for the host and another one for the device.\\nI’m not familiar with the native PyTorch profiler visualization as I am using Nsight Systems for profiling. You could check this post for instructions on how to use nsys., That makes sense, thanks.\\nOne more question, is there a limit to the number of async python calls that pytorch can do without waiting for the actual computation to be done in the GPU? It seems that it is doing multiple faster non-blocking calls to training steps (#16 and #17) before it starts to take longer in step #18, I assume waiting for GPU to finish the previous ones. In general, what is a good resource where I can learn more about how Pytorch works under the hood?\\nIn any case I will switch to nsys profiler, seems like a much better option. Thanks a lot., benoriol:\\n\\nOne more question, is there a limit to the number of async python calls that pytorch can do without waiting for the actual computation to be done in the GPU?\\n\\n\\nYes, the queue handling the CUDA kernel launches is limited and the host will be blocked if the queue is saturated.]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>Create a view using subsampling</td>\n",
       "      <td>For example with a tensor\\n[ [0,1,2,3],[4,5,6,7],[8,9,10,11],[12,13,14,15]]\\n\\ncreate a view exposing\\n[ [0,2],[4,6],[8,10],[12,14]]\\n\\nObviously this is not a reshaping with AFAIK is all you can do with view.  However, it doesn’t seem like it would be impossible so I though I would ask.</td>\n",
       "      <td>[Direct indexing should work:\\nx = torch.tensor([[0,1,2,3],[4,5,6,7],[8,9,10,11],[12,13,14,15]])\\ny = x[:, ::2]\\nprint(y)\\n# tensor([[ 0,  2],\\n#         [ 4,  6],\\n#         [ 8, 10],\\n#         [12, 14]])\\n\\ny[0, 0].fill_(100)\\nprint(x)\\n# tensor([[100,   1,   2,   3],\\n#         [  4,   5,   6,   7],\\n#         [  8,   9,  10,  11],\\n#         [ 12,  13,  14,  15]]), Yes, that can be used to create the vector of indices, and gather can then be used to subsample.]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Uncategorized</td>\n",
       "      <td>Torch uses wrong GPU</td>\n",
       "      <td>I am using a laptop with two GPUs. The first one is a Intel(R) UHD Graphics and the second one is a NVIDIA GeForce RTX 4090 Laptop GPU. I want to run a RAG application using a llama3 model using the second GPU. When I run it, the model is loaded into memory. Afterwards the second GPU is used only until the streaming of the output starts. When streaming only the first GPU is used. This can be seen by running the application and watching the performance with the task manager.\\nThe problem can be reproduced with the following code:\\nimport torch\\nimport os\\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, TextIteratorStreamer\\nfrom pathlib import Path\\n\\ntorch.set_default_device(\"cuda\")\\n\\ndir_ = Path(__file__).parent\\n\\nmodel_path = \"my_path\"\\n\\ntokenizer = AutoTokenizer.from_pretrained(model_path, device_map=\"cuda\")\\nmodel = AutoModelForCausalLM.from_pretrained(\\n        model_path,\\n        torch_dtype=torch.bfloat16,\\n        device_map=\"cuda\",\\n        load_in_8bit=True\\n)\\nmodel.generation_config.pad_token_id = tokenizer.pad_token_id\\n\\nterminators = [\\n    tokenizer.eos_token_id,\\n    tokenizer.convert_tokens_to_ids(\"&lt;|eot_id|&gt;\")\\n]\\n\\ndef respond(message):\\n\\n    messages = []\\n    user_message = {\"role\": \"user\", \"content\":\\n        \"\"\"\\n        Frage: '{query}'\\n        \"\"\".format(query=message)}\\n    messages.extend([{\"role\": \"system\", \"content\": 'Du bist ein Assistent, der Fragen beantwortet.'},\\n                        ]\\n                    )\\n    messages.append(user_message)\\n\\n    text = tokenizer.apply_chat_template(\\n          messages,\\n          tokenize=False,\\n          add_generation_prompt=True\\n          )\\n\\n    model_inputs = tokenizer([text], return_tensors=\"pt\").to('cuda:0')\\n\\n    generated_ids = model.generate(\\n          model_inputs.input_ids,\\n          do_sample=True,\\n          temperature=0.01,\\n          top_p=0.9\\n          )\\n    \\n    answer = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\\n    answer = answer.split('assistant')[-1]\\n    return answer\\n    \\nprint(respond('Welche Sehenswürdigkeiten gibt es in Berlin?'))\\n\\nI checked that Cuda is using the right device by typing python -m torch.utils.collect_env in the console. This resulted in:\\n&lt;frozen runpy&gt;:128: RuntimeWarning: 'torch.utils.collect_env' found in sys.modules after import of package 'torch.utils', but prior to execution of 'torch.utils.collect_env'; this may result in unpredictable behaviour\\nCollecting environment information...\\nPyTorch version: 2.4.0+cu124\\nIs debug build: False\\nCUDA used to build PyTorch: 12.4\\nROCM used to build PyTorch: N/A\\n\\nOS: Microsoft Windows 11 Pro\\nGCC version: Could not collect\\nClang version: Could not collect\\nCMake version: Could not collect\\nLibc version: N/A\\n\\nPython version: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)] (64-bit runtime)\\nPython platform: Windows-10-10.0.22631-SP0\\nIs CUDA available: True\\nCUDA runtime version: 12.4.131\\nCUDA_MODULE_LOADING set to: LAZY\\nGPU models and configuration: GPU 0: NVIDIA GeForce RTX 4090 Laptop GPU\\nNvidia driver version: 551.78\\ncuDNN version: Could not collect\\nHIP runtime version: N/A\\nMIOpen runtime version: N/A\\nIs XNNPACK available: True\\n\\nCPU:\\nArchitecture=9\\nCurrentClockSpeed=2200\\nDeviceID=CPU0\\nFamily=207\\nL2CacheSize=32768\\nL2CacheSpeed=\\nManufacturer=GenuineIntel\\nMaxClockSpeed=2200\\nName=13th Gen Intel(R) Core(TM) i9-13900HX\\nProcessorType=3\\nRevision=\\n\\nVersions of relevant libraries:\\n[pip3] mypy-extensions==1.0.0\\n[pip3] numpy==1.26.3\\n[pip3] onnxruntime==1.16.3\\n[pip3] torch==2.4.0+cu124\\n[pip3] torchaudio==2.4.0+cu124\\n[pip3] torchvision==0.19.0+cu124\\n[conda] Could not collect\\n\\nI also tried\\nprint(torch.cuda.is_available())\\nprint(torch.cuda.device_count())\\nprint(torch.cuda.current_device())\\nprint(torch.cuda.get_device_name(0))\\n\\nand got\\nTrue\\n1\\n0\\n'NVIDIA GeForce RTX 4090 Laptop GPU'\\n\\nAs far as I understand, everything runs with cuda and since the NVIDIA GPU is the only cuda device, only this GPU should be used.\\nDoes somebody know how to use the NVIDIA GPU only when running the application? Why is the Intel GPU used when it is not even detected by cuda?</td>\n",
       "      <td>[Lue-C:\\n\\nAfterwards the second GPU is used only until the streaming of the output starts. When streaming only the first GPU is used.\\n\\n\\nI doubt it as your Intel UHD Graphics seems to be an integrated GPU, which does not support CUDA (and I don’t know if any other Intel backends are supported on it).\\n\\n\\n\\n Lue-C:\\n\\nThis can be seen by running the application and watching the performance with the task manager.\\n\\n\\nMake sure to check the compute tab in your Task Manager or use nvidia-smi to see the utilization of your GPU., Thanks for the advice! I checked the GPU utilization with nvidia-smi and it is used indeed with performance levels P2 to P5 and a utilization of ~15% to ~50%.\\nThis is what I see in the task manager:\\ntaskmtemp1934×211 57.8 KB\\nThis implies that the code above only utilizes the NVIDIA GPU, does it?\\nOr did I miss something and the integrated GPU is slowing down the code?, Your integrated GPU doesn’t matter and won’t be used in PyTorch as it isn’t even detected. Your laptop itself will use it for visualization., Thank you, this makes sense.\\nBut with this, the above code takes 73.22s to complete and return an answer. Is this a reasonable time for a response?]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27587</th>\n",
       "      <td>complex</td>\n",
       "      <td>Complex matrix multiplication</td>\n",
       "      <td>Given the documentation stating that\\n\\nOperations on complex tensors (e.g.,  torch.mv() ,  torch.matmul() ) are likely to be faster and more memory efficient than operations on float tensors mimicking them.\\n\\nI would expect matmul to be implemented for complex tensors, however when I try to execute the following:\\na = torch.tensor([[1.4 + 3j, 2 + 5j], [1.4 + 3j, 2 + 5j]], dtype=torch.cfloat)\\na @ a\\n\\nI get RuntimeError: _th_addmm_out not supported on CPUType for ComplexFloat.\\nThis also happens when using torch.matmul or torch.mm instead of the short operator.\\nAm I doing something wrong?\\nEdit: The error occurs on both CPU and GPU.</td>\n",
       "      <td>[Update: matrix vector multiplication seems to work if explicitly done on a vector (torch.mv()) but cannot be deduced from e.g. multiplying shapes (2, 2) x (2, 1).\\nWould be really nice to know if this is expected as in “not implemented” or if this can be done differently.]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27588</th>\n",
       "      <td>complex</td>\n",
       "      <td>Making Infinity Addition Idempotent</td>\n",
       "      <td>r1 = torch.randn(5)\\nr2 = torch.tensor([-float('inf') for k in range(5)])\\ndp = 0.\\nfor i in range(r1.shape[0]):\\n    dp+=(r1[i]*r2[i])\\n\\ndp\\n\\nOutput\\ntensor(nan)\\n\\nSo it seems adding -inf multiple times gives a nan. This creates a problem while implementing masked attention.\\nIs there a way in which adding -inf multiple times still gives me -inf ? I am not looking for a hack involving some conditional expression. Perhaps, I am looking for a solution which makes -inf idempotent with respect to addition.</td>\n",
       "      <td>[Hi Circa!\\n\\n\\n\\n circa:\\n\\nr1 = torch.randn(5)\\n\\n\\n\\nIt is likely that not all of the elements of r1 have the same sign.\\nTry replacing your original first line with:\\nr1 = torch.abs (torch.randn(5))\\n\\n\\n\\ndp+=(r1[i]*r2[i])\\n\\n\\n\\n\\nLet’s say that r1[0] is positive.  Then after the first iteration, dp will be\\nequal to -inf.  If r1[1] happens to be negative, in the second iteration\\nyou will be calculating (-inf) + inf = nan, as it should be.  (And once\\ndp becomes nan, it stays nan.)\\n\\n\\ndp\\n\\nOutput\\ntensor(nan)\\n\\n\\n\\nNote, if you run your test many times (with different random values\\nfor r1, you will occasionally get -inf and inf for the result, instead\\nof nan.\\n\\n\\nSo it seems adding -inf multiple times gives a nan.\\n\\n\\nThe short answer is that you are not adding -inf multiple times.\\nYou are usually adding -inf to inf somewhere in your loop.\\nBest.\\nK. Frank, Ahh…I see.\\nThat solved it.\\nThanks a lot.]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27592</th>\n",
       "      <td>complex</td>\n",
       "      <td>How to load models on multiple gpus and forward() it?</td>\n",
       "      <td>I load my 2 model on gpu1 and gpu2. current_device is set on gpu1\\nthen I can forward model on gpu1 but cannot model on gpu2 with this error\\nRuntimeError: all tensors must be on devices[0]\\n\\nAfter I change the current device to gpu1 with this line, the same error occurs\\ntorch.cuda.set_device(1)</td>\n",
       "      <td>[did you follow PyTorch Data Parallelism tutorial?, @mmisiur yes, but I think my use case is a little bit different.\\nI want to load some models to multiple gpus respectively and run each model on its gpu.\\nThanks for reminding it., Ok, right. So it’s hard to say what is wrong without your code. But if I understand what you want to do (load one model on one gpu, second model on second gpu, and pass some input through them) I think the proper way to do this, and one that works for me is:\\n# imports\\nimport torch\\n\\n# define models\\nm0 = torch.nn.Linear(10,5)\\nm1 = torch.nn.Linear(10,5)\\n\\n# define devices\\nd0 = torch.device(\"cuda:0\")\\nd1 = torch.device(\"cuda:1\")\\n\\n# define tensors\\nt0 = torch.rand(10)\\nt1 = torch.rand(10)\\n\\n# move to devices\\nt0 = t0.to(d0)\\nt1 = t1.to(d1)\\nm0 = m0.to(d0)\\nm1 = m1.to(d1)\\n\\n# forward pass\\nout0 = m0(t0)\\nout1 = m1(t1), Oh I just noticed that I didn’t move tensors…\\nThanks!!]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27593</th>\n",
       "      <td>complex</td>\n",
       "      <td>How model is loaded on gpu?</td>\n",
       "      <td>I’m testing loading same model in gpu like this.\\nimport model\\nimport numpy as np\\n\\ntt = np.zeros((512, 512, 3), dtype=np.uint8)\\nms = {}\\nwhile True:\\n\\tfor i in range(300):\\n\\t\\tif not ms.get(i):\\n\\t\\t\\tms.update({i:model.Model()})\\n\\t\\t\\tfor k,v in ms.items():\\n\\t\\t\\t\\tv.infer(tt)\\n\\t\\t\\tprint(i, 'loaded')\\n\\t\\t\\tprint(len(ms), 'length')\\n\\nWhen I load just 1 model, it occupies 1G of GPU mem.\\nBut when i load 160 model like above it occupies just 16G of gpu mem. why usage of gpu mem is not increasing linearly?</td>\n",
       "      <td>[The first CUDA call will initialize the CUDA context, which will use some memory on your device (depending on the CUDA version, used GPU etc.).\\nYou could check the memory usage in PyTorch using print(torch.cuda.memory_allocated()).]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27594</th>\n",
       "      <td>complex</td>\n",
       "      <td>Torch Tensor from `numpy` complex not working</td>\n",
       "      <td>How much of the complex API is actually supported on Torch?\\n1.4.0 Documentation\\n&gt;&gt;&gt; torch.real(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j]))\\ntensor([ -1,  -2,  3])\\n\\nRunning on Colab, Torch version: 1.4.0\\nRuntimeError                              Traceback (most recent call last)\\n&lt;ipython-input-65-6ab8515aa959&gt; in &lt;module&gt;()\\n----&gt; 1 torch.real(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j]))\\n\\nRuntimeError: Could not infer dtype of complex</td>\n",
       "      <td>[Hey @eduardo4jesus this should work on the latest master build. I fixed it last week: https://github.com/pytorch/pytorch/pull/33361, Oh I see. I actually though about it, but then I checked that the documentation version was right. So, I got confused.\\nAny chance of having built in complex multiplication coming soon?\\nThanks a lot., yeah we are working on adding the matrix multiplication. should be out soon]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21032 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            category  \\\n",
       "0      Uncategorized   \n",
       "1      Uncategorized   \n",
       "3      Uncategorized   \n",
       "5      Uncategorized   \n",
       "7      Uncategorized   \n",
       "...              ...   \n",
       "27587        complex   \n",
       "27588        complex   \n",
       "27592        complex   \n",
       "27593        complex   \n",
       "27594        complex   \n",
       "\n",
       "                                                                                                                                       title  \\\n",
       "0      [W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]   \n",
       "1                                                                                                                   Determinism in inference   \n",
       "3                                                                                                              Weird Pytorch profiler output   \n",
       "5                                                                                                            Create a view using subsampling   \n",
       "7                                                                                                                       Torch uses wrong GPU   \n",
       "...                                                                                                                                      ...   \n",
       "27587                                                                                                          Complex matrix multiplication   \n",
       "27588                                                                                                    Making Infinity Addition Idempotent   \n",
       "27592                                                                                  How to load models on multiple gpus and forward() it?   \n",
       "27593                                                                                                            How model is loaded on gpu?   \n",
       "27594                                                                                          Torch Tensor from `numpy` complex not working   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 question  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            I got this warning at the end of each epoch when using multiple GPUs:\\n[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\\nBut it doesn’t seem to affect the training since the result is as good as it is.\\nBut I would still like to know what the probable cause is and how to solve it  \\nI simply use: model = torch.nn.DataParallel(model) to enable multi-GPUs.\\nBesides, I also added torch.multiprocessing.set_start_method('spawn', force=True) in my code. Don’t know whether it has any effect on this.\\nThank you for the answer in advance.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   I have the following code snippet. When I run the script consecutively, I get different results in prediction. Is there a setting I’m missing?\\nimport torch\\nimport numpy as np\\nimport random\\n\\n# Set the seed for all random number generators\\nseed = 42\\ntorch.manual_seed(seed)\\nrandom.seed(seed)\\nnp.random.seed(seed)\\ntorch.cuda.manual_seed(seed)\\ntorch.cuda.manual_seed_all(seed)\\n\\n# Ensure deterministic behavior\\ntorch.backends.cudnn.deterministic = True\\ntorch.backends.cudnn.benchmark = False\\n\\n# Set CUBLAS workspace config to ensure deterministic cuBLAS\\nimport os\\nos.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\\n\\ntorch.use_deterministic_algorithms(True)\\ntorch.set_num_threads(1)\\n\\n# Load the model\\nmodel = torch.jit.load('test.pt')\\nmodel = model.to(torch.device('cuda:0'))\\nmodel = model.half()\\n\\n# Create a random array\\ntorch.manual_seed(0)\\nrandom_arr = torch.randn(1,1,224, 224, 224, dtype = torch.half).to(torch.device('cuda:0'))\\npred = model(random_arr).to(torch.device('cpu')).detach().numpy()\\n\\nThe pred variable is different in each run, max. difference is about 3e-2. Any help would be appreciated. Thanks!   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Hello,\\nI am profiling my training code and I’m struggling to understand the output. The different steps seem to be taking different amount of time and I am not sure why.\\nimage3082×1044 378 KB\\nA simplified version of my code would be:\\nwith profiler.profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], ...) as p:\\n    for x, y in training_dataloader:\\n        p.step()\\n        out = model(x)\\n        loss = loss_fn(out,y)\\n        loss.backward()\\n        optim.step()\\n        optim.zero_grad()\\n\\nScheduler is set to skip_first=10, wait=5, warmup=1, active=5, repeat=1\\nIf I then add some operation that downloads something to cpu memory such as l = loss.item() after the optimizer step, I get something like this:\\nimage3048×1050 292 KB\\nIn both scenarios the average train step is the same even though each profiler step seems to vary in time in the first case.\\nI am a bit confused by this behaviour. My hypothesis is that my profiler might be measuring the async python function calls and not the actual cuda kernels. But isn’t the point of the profiler to measure the cuda kernel time? I am interested in analysing how long does my CPU and GPU take in each part of the code, and I guess here I am just seeing the CPU?\\nIf I go down below in the GPU thread part of the profiler, I get this, which I don’t understand or is giving me too little information about how long is spent in each kernel by the gpu.\\nimage4106×798 183 KB\\nNote that this screenshot is taken for the first example where i do NOT add l = loss.item() and all the different steps are taking different time in cpu time. Yet in the GPU thread they seem to be taking the same amount of time.\\nI would appreciate any insights on why this is happening or if my intuitions are correct and what is the best way to measure how long is my GPU spending in each kernel.\\nI am using a 4090 GPU and the model is a simple UNet with 128x128 image input.\\nThanks,\\nBenet   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        For example with a tensor\\n[ [0,1,2,3],[4,5,6,7],[8,9,10,11],[12,13,14,15]]\\n\\ncreate a view exposing\\n[ [0,2],[4,6],[8,10],[12,14]]\\n\\nObviously this is not a reshaping with AFAIK is all you can do with view.  However, it doesn’t seem like it would be impossible so I though I would ask.   \n",
       "7      I am using a laptop with two GPUs. The first one is a Intel(R) UHD Graphics and the second one is a NVIDIA GeForce RTX 4090 Laptop GPU. I want to run a RAG application using a llama3 model using the second GPU. When I run it, the model is loaded into memory. Afterwards the second GPU is used only until the streaming of the output starts. When streaming only the first GPU is used. This can be seen by running the application and watching the performance with the task manager.\\nThe problem can be reproduced with the following code:\\nimport torch\\nimport os\\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, TextIteratorStreamer\\nfrom pathlib import Path\\n\\ntorch.set_default_device(\"cuda\")\\n\\ndir_ = Path(__file__).parent\\n\\nmodel_path = \"my_path\"\\n\\ntokenizer = AutoTokenizer.from_pretrained(model_path, device_map=\"cuda\")\\nmodel = AutoModelForCausalLM.from_pretrained(\\n        model_path,\\n        torch_dtype=torch.bfloat16,\\n        device_map=\"cuda\",\\n        load_in_8bit=True\\n)\\nmodel.generation_config.pad_token_id = tokenizer.pad_token_id\\n\\nterminators = [\\n    tokenizer.eos_token_id,\\n    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\\n]\\n\\ndef respond(message):\\n\\n    messages = []\\n    user_message = {\"role\": \"user\", \"content\":\\n        \"\"\"\\n        Frage: '{query}'\\n        \"\"\".format(query=message)}\\n    messages.extend([{\"role\": \"system\", \"content\": 'Du bist ein Assistent, der Fragen beantwortet.'},\\n                        ]\\n                    )\\n    messages.append(user_message)\\n\\n    text = tokenizer.apply_chat_template(\\n          messages,\\n          tokenize=False,\\n          add_generation_prompt=True\\n          )\\n\\n    model_inputs = tokenizer([text], return_tensors=\"pt\").to('cuda:0')\\n\\n    generated_ids = model.generate(\\n          model_inputs.input_ids,\\n          do_sample=True,\\n          temperature=0.01,\\n          top_p=0.9\\n          )\\n    \\n    answer = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\\n    answer = answer.split('assistant')[-1]\\n    return answer\\n    \\nprint(respond('Welche Sehenswürdigkeiten gibt es in Berlin?'))\\n\\nI checked that Cuda is using the right device by typing python -m torch.utils.collect_env in the console. This resulted in:\\n<frozen runpy>:128: RuntimeWarning: 'torch.utils.collect_env' found in sys.modules after import of package 'torch.utils', but prior to execution of 'torch.utils.collect_env'; this may result in unpredictable behaviour\\nCollecting environment information...\\nPyTorch version: 2.4.0+cu124\\nIs debug build: False\\nCUDA used to build PyTorch: 12.4\\nROCM used to build PyTorch: N/A\\n\\nOS: Microsoft Windows 11 Pro\\nGCC version: Could not collect\\nClang version: Could not collect\\nCMake version: Could not collect\\nLibc version: N/A\\n\\nPython version: 3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)] (64-bit runtime)\\nPython platform: Windows-10-10.0.22631-SP0\\nIs CUDA available: True\\nCUDA runtime version: 12.4.131\\nCUDA_MODULE_LOADING set to: LAZY\\nGPU models and configuration: GPU 0: NVIDIA GeForce RTX 4090 Laptop GPU\\nNvidia driver version: 551.78\\ncuDNN version: Could not collect\\nHIP runtime version: N/A\\nMIOpen runtime version: N/A\\nIs XNNPACK available: True\\n\\nCPU:\\nArchitecture=9\\nCurrentClockSpeed=2200\\nDeviceID=CPU0\\nFamily=207\\nL2CacheSize=32768\\nL2CacheSpeed=\\nManufacturer=GenuineIntel\\nMaxClockSpeed=2200\\nName=13th Gen Intel(R) Core(TM) i9-13900HX\\nProcessorType=3\\nRevision=\\n\\nVersions of relevant libraries:\\n[pip3] mypy-extensions==1.0.0\\n[pip3] numpy==1.26.3\\n[pip3] onnxruntime==1.16.3\\n[pip3] torch==2.4.0+cu124\\n[pip3] torchaudio==2.4.0+cu124\\n[pip3] torchvision==0.19.0+cu124\\n[conda] Could not collect\\n\\nI also tried\\nprint(torch.cuda.is_available())\\nprint(torch.cuda.device_count())\\nprint(torch.cuda.current_device())\\nprint(torch.cuda.get_device_name(0))\\n\\nand got\\nTrue\\n1\\n0\\n'NVIDIA GeForce RTX 4090 Laptop GPU'\\n\\nAs far as I understand, everything runs with cuda and since the NVIDIA GPU is the only cuda device, only this GPU should be used.\\nDoes somebody know how to use the NVIDIA GPU only when running the application? Why is the Intel GPU used when it is not even detected by cuda?   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ...   \n",
       "27587                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Given the documentation stating that\\n\\nOperations on complex tensors (e.g.,  torch.mv() ,  torch.matmul() ) are likely to be faster and more memory efficient than operations on float tensors mimicking them.\\n\\nI would expect matmul to be implemented for complex tensors, however when I try to execute the following:\\na = torch.tensor([[1.4 + 3j, 2 + 5j], [1.4 + 3j, 2 + 5j]], dtype=torch.cfloat)\\na @ a\\n\\nI get RuntimeError: _th_addmm_out not supported on CPUType for ComplexFloat.\\nThis also happens when using torch.matmul or torch.mm instead of the short operator.\\nAm I doing something wrong?\\nEdit: The error occurs on both CPU and GPU.   \n",
       "27588                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     r1 = torch.randn(5)\\nr2 = torch.tensor([-float('inf') for k in range(5)])\\ndp = 0.\\nfor i in range(r1.shape[0]):\\n    dp+=(r1[i]*r2[i])\\n\\ndp\\n\\nOutput\\ntensor(nan)\\n\\nSo it seems adding -inf multiple times gives a nan. This creates a problem while implementing masked attention.\\nIs there a way in which adding -inf multiple times still gives me -inf ? I am not looking for a hack involving some conditional expression. Perhaps, I am looking for a solution which makes -inf idempotent with respect to addition.   \n",
       "27592                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          I load my 2 model on gpu1 and gpu2. current_device is set on gpu1\\nthen I can forward model on gpu1 but cannot model on gpu2 with this error\\nRuntimeError: all tensors must be on devices[0]\\n\\nAfter I change the current device to gpu1 with this line, the same error occurs\\ntorch.cuda.set_device(1)   \n",
       "27593                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            I’m testing loading same model in gpu like this.\\nimport model\\nimport numpy as np\\n\\ntt = np.zeros((512, 512, 3), dtype=np.uint8)\\nms = {}\\nwhile True:\\n\\tfor i in range(300):\\n\\t\\tif not ms.get(i):\\n\\t\\t\\tms.update({i:model.Model()})\\n\\t\\t\\tfor k,v in ms.items():\\n\\t\\t\\t\\tv.infer(tt)\\n\\t\\t\\tprint(i, 'loaded')\\n\\t\\t\\tprint(len(ms), 'length')\\n\\nWhen I load just 1 model, it occupies 1G of GPU mem.\\nBut when i load 160 model like above it occupies just 16G of gpu mem. why usage of gpu mem is not increasing linearly?   \n",
       "27594                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            How much of the complex API is actually supported on Torch?\\n1.4.0 Documentation\\n>>> torch.real(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j]))\\ntensor([ -1,  -2,  3])\\n\\nRunning on Colab, Torch version: 1.4.0\\nRuntimeError                              Traceback (most recent call last)\\n<ipython-input-65-6ab8515aa959> in <module>()\\n----> 1 torch.real(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j]))\\n\\nRuntimeError: Could not infer dtype of complex   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     all_answers  \\\n",
       "0      [Are you seeing the same message, if you remove the multiprocessing code (I assume this is triggering it)?, Sorry for my late response and thank you for the reply!\\nI pinned the trigger of this warning. It happens if I set num_workers > 0 in torch.utils.data.DataLoader, instead of being caused by nn.DataParallel().\\nAny idea how to fix it? Is it probably due to that I set torch.multiprocessing.set_start_method('spawn', force=True)?, I have issued the same problem when setting num of workers to more then 0. @ptrblck, any solution ?, Unfortunately, I don’t have suggestions, as I don’t fully understand the use case of using torch.multiprocessing as well as multiple workers (which itself will use multiple processes), so could you explain the use case a bit more?, Hi @ptrblck, I came across the same issue and was intrigued by your remark:\\n\\n\\n\\n ptrblck:\\n\\nI don’t fully understand the use case of using torch.multiprocessing as well as multiple workers\\n\\n\\nFor one, isn’t it good to be able to process/load the data using a separate process, apart from the training process(es), in order to not tax them with extra processing load? Further, although it’s not my use case, loading the data might involve some heavy preprocessing, warranting even more than one data loader workers per training process; e.g. in the case in of some vision applications.\\nMaybe you have a completely different idea about this and give us your insight in to this topic.\\nThanks in advance., I totally agree with you and also think that multiple processes by themselves are useful, should be used for the data loading and process, and would yield a speedup in the overall training pipeline.\\nThis can be easily achieved with the num_workers argument of the DataLoader.\\nMy comment might not have been clear enough, but I was wondering about the use case to use the multiprocessing package manually in the training script as well as multiple workers (which will again spawn multiple processes, so you would end up with a “nested” multiprocessing workload), as I would imagine that using the simpler approach of setting num_workers>=1 should already do the job., Ah, ok, sorry, I didn’t notice the part about using the multiprocessing package separately. I think this is because I had the same issue just using DDP and Dataloaders with num_workers > 0. I get these errors just before my script exits; I already am a good citizen by using dist.barrier() to wait for all training processes to complete before exiting.\\nWhen I set the num_workers to zero the script exits smoothly without any errors. In the past I have often used multiple DataLoader workers in a DDP context and never had this issue. I’m wondering if this is something that sneaked in to a recent Pytorch release or is related to recent a CUDA version?\\nMy setup:\\n| NVIDIA-SMI 470.86 Driver Version: 470.86 CUDA Version: 11.4     |\\n\\n$ pip show torch\\nName: torch\\nVersion: 1.10.0\\n\\nThis is on a 4x V100 machine with Ubuntu.\\nIt might also be in my script of course., Ok, I dove a bit more in to this, and found the issue. In this particular instance I am using a model library where the author unfortunately had added the batch collate function as a method to the model class. Because of this the model self is also transported to the DataLoader workers.\\nWhen the training scripts exits the DataLoader worker processes are killed too, without properly dealing with the Tensors that are copied to the worker.\\nI refactored all the batch collating code out of the model class and thus made it independent of the self of the model instance. This resolved the issue, exiting the script is very smooth now!\\nSo, if anyone gets this error, it could be because your are copying the model over to the DataLoader workers without knowing it., Hi @visionscaper, I’m encountering the same issue. I’m currently using pytorch lightning to write my model. When I set the num_worker > 0 in the dataloader, the warning will occur. I’m a beginner in pytorch. Could you give me some example that how did you refactor your batch collating code out of model class? I don’t know how to do it., Hi @sjtuhl, if you have a similar issue to mine, somehow your model is linked to your dataset, collate_fn or other object given to a DataLoader. Because of this, when you set num_worker > 0, the model is copied to the DataLoader workers. For instance, if your dataset is a property of your model class instance (which is just bad design), not only your dataset is copied to the workers, but everything it is “attached” to as well.\\nI hope this makes sense to you. I can’t really help you without inspecting your code., Hi @visionscaper, I have the same issue as you. My data collate fn is written inside the dataset model. There are some tensors my collate_fn need, stored in the dataset model. I wonder if there is a way to avoid moving the collate_fn out and escape the error?, This warning is caused by tensors (or other objects) that are not being properly cleaned up (released) on the CUDA device before the process they belonged to was terminated.\\nAs it was for me in my case, and seems to be the case for mostly everyone else, the culprit behind this warning has to do with moving objects to, or owning objects on, the CUDA device from inside of one of the DataLoader worker processes, and the worker process being terminated before the  objects are released from CUDA.\\nMoving tensors to CUDA inside a collate_fn that is passed to a DataLoader where num_workers > 0 - which just means that a child process will be created for each worker - is an example of this, and is exactly what I was doing. In my training loop then, after all the training samples were iterated through, my DataLoader worker processes would be terminated and I would get this warning.\\nAs tempting as it is to move batches to CUDA inside the collate_fn, and though it may even provide some performance gains, the potential for a memory leak or some other resource management issue along with the annoying warning made me rethink my strategy. I ended up just relocating this logic to the first line in my training loop (on CPU - main process) where I move each batch to CUDA before my forward pass which I think is generally recommended anyway - never looked back since.\\nAlternatively, if you really wanted to, you could keep whatever objects you want on the CUDA device inside your DataLoader worker processes if you set persistent_workers=True in your DataLoader constructor and not encounter this warning until your DataLoader is entirely deallocated. You may encounter other issues though like running out of memory on the GPU, but I think for some use cases, maybe doing this could be beneficial.\\nHope this helps.]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [Could you post a minimal and executable code snippet reproducing the issue?, Thanks for your response. Here are two scripts, please save them as script_1.py and script_2.py in the working directory. For this experiment, I’m using a model from huggingface, but the results are similar with my own segmentation model (nnU-Net).\\n# Save this as script_1.py\\n\\nimport torch\\nimport numpy as np\\nimport random\\nimport requests\\nimport pickle\\nimport argparse\\n\\nif __name__ == '__main__':\\n\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument(\"--result_filename\", help=\"location to save the result prediction\")\\n\\n    args = parser.parse_args()\\n    \\n    # Set the seed for all random number generators\\n    seed = 42\\n    torch.manual_seed(seed)\\n    random.seed(seed)\\n    np.random.seed(seed)\\n    torch.cuda.manual_seed(seed)\\n    torch.cuda.manual_seed_all(seed)\\n\\n    # Ensure deterministic behavior\\n    torch.backends.cudnn.deterministic = True\\n    torch.backends.cudnn.benchmark = False\\n\\n    # Set CUBLAS workspace config to ensure deterministic cuBLAS\\n    import os\\n    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\\n\\n    torch.use_deterministic_algorithms(True)\\n    torch.set_num_threads(1)\\n\\n    # Download the file\\n    url = 'https://huggingface.co/spaces/Xajimel/Practica3/resolve/main/unet.pth'\\n    response = requests.get(url)\\n    with open('model.pt', 'wb') as f:\\n        f.write(response.content)\\n\\n    model = torch.jit.load('model.pt')\\n    model = model.to(torch.device('cuda:0'))\\n    model = model.half()\\n\\n    # Create a random array\\n    torch.manual_seed(0)\\n    random_arr = torch.randn(1, 3, 224, 224, dtype = torch.half).to(torch.device('cuda:0'))\\n    pred = model(random_arr).to(torch.device('cpu')).detach().numpy()\\n\\n    with open(args.result_filename, 'wb') as f:\\n        pickle.dump(pred, f)\\n\\n# Save this as script_2.py\\n\\nimport pickle\\nimport numpy as np\\n\\nwith open('pred1.pkl', 'rb') as f:\\n    a = pickle.load(f)\\n\\nwith open('pred2.pkl', 'rb') as f:\\n    b = pickle.load(f)\\n\\nprint('Length of a: ', len(a))\\nprint('Length of b: ', len(b))\\n\\nprint('Shape of first element in a: ', a[0].shape)\\nprint('Shape of first element in b: ', b[0].shape)\\n\\ndiff = a[0] - b[0]\\n\\nprint('Min diff: ', np.min(diff))\\nprint('Max diff: ', np.max(diff))\\n\\nRun this with the following commands.\\npython script_1.py --result_filename pred1.pkl\\npython script_1.py --result_filename pred2.pkl\\npython script_2.py\\n\\nSomething I found interesting was that if I change the url in script_1.py to a different model (say this one), I see no differences in the prediction.\\nI wonder if the issue then is non-determinism in some layers in the nnU-Net model or the way I’m saving the model. This is how I save the model.\\nself.network = self.network.to(self.device)\\nself.network.eval()\\ntorch.use_deterministic_algorithms(True)\\ntraced_model = torch.jit.trace(self.network, torch.randn(1, 1, 224, 224, 224).to(self.device))\\ntorch.jit.save(traced_model, 'model.pt')\\n\\nLet me know what you think or if you need some more info. Thanks!, I cannot reproduce the issue and see:\\nLength of a:  1\\nLength of b:  1\\nShape of first element in a:  (5, 224, 224)\\nShape of first element in b:  (5, 224, 224)\\nMin diff:  0.0\\nMax diff:  0.0, This is what I see. I’m on torch 2.3.0+cu121 if that helps.\\nLength of a:  1\\nLength of b:  1\\nShape of first element in a:  (5, 224, 224)\\nShape of first element in b:  (5, 224, 224)\\nMin diff:  -0.01563\\nMax diff:  0.01172, @ptrblck On the machine that I was initially testing on, I see the issue on torch 2.3.0+cu121 and torch 2.4.0+cu121. On another machine, I don’t see the issue in either versions. These machines have different GPUs (earlier: A40, now: RTX 3050 Ti).\\nCould the underlying GPU make a difference?]   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [benoriol:\\n\\nIf I then add some operation that downloads something to cpu memory such as l = loss.item() after the optimizer step, I get something like this:\\n\\n\\nThis is expected since the item() call is synchronizing the GPU.\\n\\n\\n\\n benoriol:\\n\\nI am a bit confused by this behaviour. My hypothesis is that my profiler might be measuring the async python function calls and not the actual cuda kernels.\\n\\n\\nYes, this seems to be the case and I would expect to see different time lines: one for the host and another one for the device.\\nI’m not familiar with the native PyTorch profiler visualization as I am using Nsight Systems for profiling. You could check this post for instructions on how to use nsys., That makes sense, thanks.\\nOne more question, is there a limit to the number of async python calls that pytorch can do without waiting for the actual computation to be done in the GPU? It seems that it is doing multiple faster non-blocking calls to training steps (#16 and #17) before it starts to take longer in step #18, I assume waiting for GPU to finish the previous ones. In general, what is a good resource where I can learn more about how Pytorch works under the hood?\\nIn any case I will switch to nsys profiler, seems like a much better option. Thanks a lot., benoriol:\\n\\nOne more question, is there a limit to the number of async python calls that pytorch can do without waiting for the actual computation to be done in the GPU?\\n\\n\\nYes, the queue handling the CUDA kernel launches is limited and the host will be blocked if the queue is saturated.]   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [Direct indexing should work:\\nx = torch.tensor([[0,1,2,3],[4,5,6,7],[8,9,10,11],[12,13,14,15]])\\ny = x[:, ::2]\\nprint(y)\\n# tensor([[ 0,  2],\\n#         [ 4,  6],\\n#         [ 8, 10],\\n#         [12, 14]])\\n\\ny[0, 0].fill_(100)\\nprint(x)\\n# tensor([[100,   1,   2,   3],\\n#         [  4,   5,   6,   7],\\n#         [  8,   9,  10,  11],\\n#         [ 12,  13,  14,  15]]), Yes, that can be used to create the vector of indices, and gather can then be used to subsample.]   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [Lue-C:\\n\\nAfterwards the second GPU is used only until the streaming of the output starts. When streaming only the first GPU is used.\\n\\n\\nI doubt it as your Intel UHD Graphics seems to be an integrated GPU, which does not support CUDA (and I don’t know if any other Intel backends are supported on it).\\n\\n\\n\\n Lue-C:\\n\\nThis can be seen by running the application and watching the performance with the task manager.\\n\\n\\nMake sure to check the compute tab in your Task Manager or use nvidia-smi to see the utilization of your GPU., Thanks for the advice! I checked the GPU utilization with nvidia-smi and it is used indeed with performance levels P2 to P5 and a utilization of ~15% to ~50%.\\nThis is what I see in the task manager:\\ntaskmtemp1934×211 57.8 KB\\nThis implies that the code above only utilizes the NVIDIA GPU, does it?\\nOr did I miss something and the integrated GPU is slowing down the code?, Your integrated GPU doesn’t matter and won’t be used in PyTorch as it isn’t even detected. Your laptop itself will use it for visualization., Thank you, this makes sense.\\nBut with this, the above code takes 73.22s to complete and return an answer. Is this a reasonable time for a response?]   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ...   \n",
       "27587                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [Update: matrix vector multiplication seems to work if explicitly done on a vector (torch.mv()) but cannot be deduced from e.g. multiplying shapes (2, 2) x (2, 1).\\nWould be really nice to know if this is expected as in “not implemented” or if this can be done differently.]   \n",
       "27588                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          [Hi Circa!\\n\\n\\n\\n circa:\\n\\nr1 = torch.randn(5)\\n\\n\\n\\nIt is likely that not all of the elements of r1 have the same sign.\\nTry replacing your original first line with:\\nr1 = torch.abs (torch.randn(5))\\n\\n\\n\\ndp+=(r1[i]*r2[i])\\n\\n\\n\\n\\nLet’s say that r1[0] is positive.  Then after the first iteration, dp will be\\nequal to -inf.  If r1[1] happens to be negative, in the second iteration\\nyou will be calculating (-inf) + inf = nan, as it should be.  (And once\\ndp becomes nan, it stays nan.)\\n\\n\\ndp\\n\\nOutput\\ntensor(nan)\\n\\n\\n\\nNote, if you run your test many times (with different random values\\nfor r1, you will occasionally get -inf and inf for the result, instead\\nof nan.\\n\\n\\nSo it seems adding -inf multiple times gives a nan.\\n\\n\\nThe short answer is that you are not adding -inf multiple times.\\nYou are usually adding -inf to inf somewhere in your loop.\\nBest.\\nK. Frank, Ahh…I see.\\nThat solved it.\\nThanks a lot.]   \n",
       "27592                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [did you follow PyTorch Data Parallelism tutorial?, @mmisiur yes, but I think my use case is a little bit different.\\nI want to load some models to multiple gpus respectively and run each model on its gpu.\\nThanks for reminding it., Ok, right. So it’s hard to say what is wrong without your code. But if I understand what you want to do (load one model on one gpu, second model on second gpu, and pass some input through them) I think the proper way to do this, and one that works for me is:\\n# imports\\nimport torch\\n\\n# define models\\nm0 = torch.nn.Linear(10,5)\\nm1 = torch.nn.Linear(10,5)\\n\\n# define devices\\nd0 = torch.device(\"cuda:0\")\\nd1 = torch.device(\"cuda:1\")\\n\\n# define tensors\\nt0 = torch.rand(10)\\nt1 = torch.rand(10)\\n\\n# move to devices\\nt0 = t0.to(d0)\\nt1 = t1.to(d1)\\nm0 = m0.to(d0)\\nm1 = m1.to(d1)\\n\\n# forward pass\\nout0 = m0(t0)\\nout1 = m1(t1), Oh I just noticed that I didn’t move tensors…\\nThanks!!]   \n",
       "27593                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [The first CUDA call will initialize the CUDA context, which will use some memory on your device (depending on the CUDA version, used GPU etc.).\\nYou could check the memory usage in PyTorch using print(torch.cuda.memory_allocated()).]   \n",
       "27594                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               [Hey @eduardo4jesus this should work on the latest master build. I fixed it last week: https://github.com/pytorch/pytorch/pull/33361, Oh I see. I actually though about it, but then I checked that the documentation version was right. So, I got confused.\\nAny chance of having built in complex multiplication coming soon?\\nThanks a lot., yeah we are working on adding the matrix multiplication. should be out soon]   \n",
       "\n",
       "       list_length  \n",
       "0               12  \n",
       "1                5  \n",
       "3                3  \n",
       "5                2  \n",
       "7                4  \n",
       "...            ...  \n",
       "27587            1  \n",
       "27588            2  \n",
       "27592            4  \n",
       "27593            1  \n",
       "27594            3  \n",
       "\n",
       "[21032 rows x 5 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=['title', 'question'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Data (Convert to lowercase, Remove special characters and digit and Remove extra whitespaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       question  \\\n",
      "0  I got this warning at the end of each epoch when using multiple GPUs:\\n[W CudaIPCTypes.cpp:22] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]\\nBut it doesn’t seem to affect the training since the result is as good as it is.\\nBut I would still like to know what the probable cause is and how to solve it  \\nI simply use: model = torch.nn.DataParallel(model) to enable multi-GPUs.\\nBesides, I also added torch.multiprocessing.set_start_method('spawn', force=True) in my code. Don’t know whether it has any effect on this.\\nThank you for the answer in advance.   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                cleaned_question  \n",
      "0  i got this warning at the end of each epoch when using multiple gpus: [w cudaipctypes.cpp:22] producer process has been terminated before all shared cuda tensors released. see note [sharing cuda tensors] but it doesnt seem to affect the training since the result is as good as it is. but i would still like to know what the probable cause is and how to solve it i simply use: model torch.nn.dataparallel(model) to enable multi-gpus. besides, i also added torch.multiprocessing.set_start_method(spawn, forcetrue) in my code. dont know whether it has any effect on this. thank you for the answer in advance.  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase for standardization\n",
    "    text = text.lower()\n",
    "    # Remove certain special characters but keep punctuation used in code\n",
    "    text = re.sub(r'[^a-z0-9\\s.,:;(){}\\[\\]@#_-]', '', text)  # Keep common symbols used in code\n",
    "    # Remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Apply to questions (and potentially answers later)\n",
    "df['cleaned_question'] = df['question'].apply(preprocess_text)\n",
    "\n",
    "# Display the comparison between cleaned and original text\n",
    "comparison_df = df[['question', 'cleaned_question']].head(1)\n",
    "print(comparison_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Uncategorized', 'vision', 'projects', 'autograd', 'data',\n",
       "       'reinforcement-learning', 'nlp', 'distributed', 'quantization',\n",
       "       'deployment', 'PyTorch Live', 'audio', 'windows',\n",
       "       'mixed-precision', 'Memory Format', 'jit', 'Mobile',\n",
       "       'torch.package / torch::deploy', 'Mac OS X', 'Opacus', 'Captum',\n",
       "       'tensorboard', 'ignite', 'glow', 'xla', 'Site Feedback', 'complex'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "categories_encoded = encoder.fit_transform(df['category'].values.reshape(-1, 1)).toarray()\n",
    "categories_encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use Bert Tokenizer (BERT’s strong contextual understanding and performance in these types of tasks make it a suitable choice.)\n",
    "\n",
    "https://gluebenchmark.com/leaderboard\n",
    "QNLI is the most relevant since it directly evaluates question-answering capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
