{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_TOKEN = '<>'  # Replace with your token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Sleeping for 587.3035609722137 seconds.\n",
      "Rate limit exceeded. Sleeping for 507.8897547721863 seconds.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Constants\n",
    "GITHUB_API_URL = \"https://api.github.com\"\n",
    "REPO_OWNER = \"pytorch\"\n",
    "REPO_NAME = \"pytorch\"\n",
    "ISSUES_PER_PAGE = 30\n",
    "SAVE_FILE = \"issues_data.json\"\n",
    "CHECKPOINT_FILE = \"checkpoint.json\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"Accept\": \"application/vnd.github+json\",\n",
    "    \"Authorization\": f\"Bearer {ACCESS_TOKEN}\",\n",
    "    \"X-GitHub-Api-Version\": \"2022-11-28\"\n",
    "}\n",
    "\n",
    "# Ensure the data_scripts directory exists\n",
    "if not os.path.exists('data_scripts'):\n",
    "    os.makedirs('data_scripts')\n",
    "\n",
    "# Function to check rate limits\n",
    "def check_rate_limit():\n",
    "    response = requests.get(f\"{GITHUB_API_URL}/rate_limit\", headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        rate_limit = response.json()\n",
    "        if 'resources' in rate_limit and 'core' in rate_limit['resources']:\n",
    "            remaining = rate_limit['resources']['core']['remaining']\n",
    "            reset_time = rate_limit['resources']['core']['reset']\n",
    "            return remaining, reset_time\n",
    "    return None, None\n",
    "\n",
    "# Function to fetch issues from GitHub\n",
    "def fetch_issues(page):\n",
    "    url = f\"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues\"\n",
    "    params = {\n",
    "        \"state\": \"all\",\n",
    "        \"per_page\": ISSUES_PER_PAGE,\n",
    "        \"page\": page\n",
    "    }\n",
    "    response = requests.get(url, headers=HEADERS, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "# Function to fetch comments for a specific issue with error handling\n",
    "def fetch_comments(issue_number, page=1):\n",
    "    url = f\"{GITHUB_API_URL}/repos/{REPO_OWNER}/{REPO_NAME}/issues/{issue_number}/comments\"\n",
    "    comments = []\n",
    "    while True:\n",
    "        params = {\"per_page\": ISSUES_PER_PAGE, \"page\": page}\n",
    "        try:\n",
    "            response = requests.get(url, headers=HEADERS, params=params)\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            if response.status_code == 403:\n",
    "                remaining, reset_time = check_rate_limit()\n",
    "                if remaining == 0:\n",
    "                    sleep_time = reset_time - time.time() + 10\n",
    "                    print(f\"Rate limit exceeded. Sleeping for {sleep_time} seconds.\")\n",
    "                    time.sleep(sleep_time)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"HTTPError 403 Forbidden: Retrying after delay...\")\n",
    "                    time.sleep(60)  # wait before retrying\n",
    "                    continue\n",
    "            elif response.status_code == 401:\n",
    "                print(f\"HTTPError 401 Unauthorized: Please check your access token.\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"An error occurred: {err}\")\n",
    "                break\n",
    "        page_comments = response.json()\n",
    "        if not page_comments:\n",
    "            break\n",
    "        comments.extend(page_comments)\n",
    "        page += 1\n",
    "    return comments\n",
    "\n",
    "# Function to identify useful comments\n",
    "def is_useful_comment(comment):\n",
    "    useful_patterns = [\n",
    "        r'\\bsolution\\b', r'\\bworkaround\\b', r'\\bresolved\\b',\n",
    "        r'\\bfixed\\b', r'\\bimplemented\\b', r'\\btemporary fix\\b',\n",
    "        r'\\bpatch\\b', r'\\bPR\\b', r'\\bpull request\\b', r'\\bcommit\\b'\n",
    "    ]\n",
    "    for pattern in useful_patterns:\n",
    "        if re.search(pattern, comment['body'], re.IGNORECASE):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Function to format issue data in Q&A style\n",
    "def format_issue_qa(issue):\n",
    "    question = {\n",
    "        \"issue_number\": issue[\"number\"],\n",
    "        \"question\": {\n",
    "            \"title\": issue[\"title\"],\n",
    "            \"body\": issue[\"body\"],\n",
    "            \"user\": {\n",
    "                \"login\": issue[\"user\"][\"login\"],\n",
    "                \"html_url\": issue[\"user\"][\"html_url\"]\n",
    "            },\n",
    "            \"created_at\": issue[\"created_at\"],\n",
    "            \"state\": issue[\"state\"]\n",
    "        },\n",
    "        \"answers\": []\n",
    "    }\n",
    "    comments = fetch_comments(issue['number'])\n",
    "    for comment in comments:\n",
    "        if is_useful_comment(comment):\n",
    "            answer = {\n",
    "                \"body\": comment[\"body\"],\n",
    "                \"user\": {\n",
    "                    \"login\": comment[\"user\"][\"login\"],\n",
    "                    \"html_url\": comment[\"user\"][\"html_url\"]\n",
    "                },\n",
    "                \"created_at\": comment[\"created_at\"]\n",
    "            }\n",
    "            question[\"answers\"].append(answer)\n",
    "    return question\n",
    "\n",
    "# Function to save data incrementally\n",
    "def save_data(data):\n",
    "    if os.path.exists(SAVE_FILE):\n",
    "        with open(SAVE_FILE, 'r') as file:\n",
    "            existing_data = json.load(file)\n",
    "        existing_data.extend(data)\n",
    "    else:\n",
    "        existing_data = data\n",
    "    with open(SAVE_FILE, 'w') as file:\n",
    "        json.dump(existing_data, file, indent=4)\n",
    "\n",
    "# Function to save checkpoint\n",
    "def save_checkpoint(page, issue_number):\n",
    "    checkpoint = {\n",
    "        \"page\": page,\n",
    "        \"issue_number\": issue_number\n",
    "    }\n",
    "    with open(CHECKPOINT_FILE, 'w') as file:\n",
    "        json.dump(checkpoint, file)\n",
    "\n",
    "# Function to load checkpoint\n",
    "def load_checkpoint():\n",
    "    if os.path.exists(CHECKPOINT_FILE):\n",
    "        with open(CHECKPOINT_FILE, 'r') as file:\n",
    "            checkpoint = json.load(file)\n",
    "        return checkpoint[\"page\"], checkpoint[\"issue_number\"]\n",
    "    return 1, None\n",
    "\n",
    "# Function to load the last processed issue number from existing data\n",
    "def load_last_issue_number():\n",
    "    if os.path.exists(SAVE_FILE):\n",
    "        with open(SAVE_FILE, 'r') as file:\n",
    "            existing_data = json.load(file)\n",
    "        return existing_data[-1]['issue_number'] if existing_data else None\n",
    "    return None\n",
    "\n",
    "# Main function to fetch and process issues\n",
    "def main():\n",
    "    page, last_issue_number = load_checkpoint()\n",
    "    if last_issue_number is None:\n",
    "        last_issue_number = load_last_issue_number()\n",
    "    all_issues = []\n",
    "\n",
    "    while True:\n",
    "        remaining, reset_time = check_rate_limit()\n",
    "        if remaining is not None and reset_time is not None:\n",
    "            if remaining < 10:\n",
    "                sleep_time = reset_time - time.time() + 10\n",
    "                print(f\"Rate limit exceeded. Sleeping for {sleep_time} seconds.\")\n",
    "                time.sleep(sleep_time)\n",
    "\n",
    "        try:\n",
    "            issues = fetch_issues(page)\n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            print(f\"An error occurred while fetching issues: {err}\")\n",
    "            save_checkpoint(page, last_issue_number)\n",
    "            break\n",
    "\n",
    "        if not issues:\n",
    "            break\n",
    "\n",
    "        for issue in issues:\n",
    "            if last_issue_number and issue[\"number\"] <= last_issue_number:\n",
    "                continue\n",
    "            try:\n",
    "                formatted_issue = format_issue_qa(issue)\n",
    "                all_issues.append(formatted_issue)\n",
    "                save_checkpoint(page, issue[\"number\"])\n",
    "            except requests.exceptions.HTTPError as err:\n",
    "                print(f\"An error occurred while fetching comments for issue {issue['number']}: {err}\")\n",
    "                save_checkpoint(page, issue[\"number\"])\n",
    "                break\n",
    "\n",
    "        save_data(all_issues)\n",
    "        page += 1\n",
    "        last_issue_number = None  # Reset last_issue_number after processing a full page\n",
    "        time.sleep(1)  # To avoid secondary rate limits\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [401]>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add logging\n",
    "# turn this into class\n",
    "# add hf code here\n",
    "# add docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
